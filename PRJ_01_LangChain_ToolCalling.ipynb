{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1cf819",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0cb932",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "id": "423dec5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T05:25:24.755473Z",
     "start_time": "2025-04-11T05:25:24.717635Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "b00b09cb",
   "metadata": {},
   "source": [
    "`(2) 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "id": "54412ba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T05:25:28.118640Z",
     "start_time": "2025-04-11T05:25:28.107134Z"
    }
   },
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "50e67655",
   "metadata": {},
   "source": [
    "## 2. 도구 호출 (Tool Calling)\n",
    "- 도구 호출은 LLM이 특정 작업을 수행하기 위해 외부 기능을 호출하는 기능\n",
    "- 이를 통해 LLM은 외부 API 통합 등 더 복잡한 작업을 수행할 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdccc6b",
   "metadata": {},
   "source": [
    "### 2-1. 랭체인 내장 도구\n",
    "- Tavily 웹 검색 도구 (예시)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7e257",
   "metadata": {},
   "source": [
    "`(1) 도구(tool) 정의하기`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T05:25:30.140342Z",
     "start_time": "2025-04-11T05:25:30.132857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"TAVILY_API_KEY\"]"
   ],
   "id": "31b6b903e3c18f27",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T05:25:41.065173Z",
     "start_time": "2025-04-11T05:25:31.769737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "# 검색할 쿼리 설정\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "\n",
    "# Tavily 검색 도구 초기화 (최대 2개의 결과 반환)\n",
    "web_search = TavilySearchResults(max_results=2)\n",
    "\n",
    "# 웹 검색 실행\n",
    "search_results = web_search.invoke(query)"
   ],
   "id": "5697979c2eba3d92",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "7c85ed38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T05:25:59.918706Z",
     "start_time": "2025-04-11T05:25:58.076320Z"
    }
   },
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "# 검색할 쿼리 설정\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "\n",
    "# Tavily 검색 도구 초기화 (최대 2개의 결과 반환)\n",
    "web_search = TavilySearchResults(max_results=2)\n",
    "\n",
    "# 웹 검색 실행\n",
    "search_results = web_search.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "for result in search_results:\n",
    "    print(result)  \n",
    "    print(\"-\" * 100)  "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://2.jkamor.com/entry/%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%81%AC%EC%99%80-%EC%9E%98-%EC%96%B4%EC%9A%B8%EB%A6%AC%EB%8A%94-%EC%99%80%EC%9D%B8-%EC%B6%94%EC%B2%9C', 'content': '레드 와인: 까베르네 소비뇽, 메를로, 피노 누아, 쉬라즈, 시라, 템프라니요 · 화이트 와인: 샤르도네, 소비뇽 블랑, 피노 그리지오, 리슬링, 게뷔르츠트라'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'url': 'https://www.wineandnews.com/ko/ranking/10-perfect-wine-pairing-with-salisbury-steak', 'content': '샤르도네가 마음에 들지 않는다면 다양한 요리와 잘 어울리는 다른 화이트 와인도 몇 가지 있습니다. 피노 그리지오도 훌륭한 대안으로, 산뜻한 산미와 깨끗하고 상쾌한 미네랄이 풍부한 풍미를 효과적으로 차단하고 입안을 깨끗하게 해줍니다. 소비뇽 블랑도 훌륭한 선택으로, 생생한 산도와 상큼한 시트러스 향으로 무거운 요리와 균형을 이루는 데 도움이 됩니다. 조금 더 식감을 즐기신다면 밝은 허브 향의 베르멘티노도 잘 어울릴 수 있습니다. 또는 그뤼너 벨트리너는 다양한 맛을 향상시켜주는 후추, 감귤류의 특성을 제공합니다. 이러한 와인들은 각각 독특한 프로필을 가지고 있으므로 음식과 즐거운 페어링을 할 수 있죠.\\n솔즈베리 스테이크와 어울리는 와인 추천 10선\\n1. 페트러스(프랑스 보르도)\\n- 유형: 레드(메를로) [...] 레드 와인은 솔즈베리 스테이크와 같은 고기 요리에 어울리는 환상적인 선택입니다. 고기의 풍부함과 균형을 이루는 대담한 풍미와 타닌 때문입니다. 고전적인 페어링을 원하신다면 카베르네 소비뇽을 고려해 보세요. 강렬한 프로필과 다크 프루트 향이 스테이크의 풍미를 더해줍니다. 메를로는 또 다른 훌륭한 선택으로, 더 부드러운 질감과 요리와 아름답게 조화를 이루는 자두 향을 제공합니다. 조금 더 복잡한 것을 선호하신다면 말벡의 흙 냄새와 다크 베리 향이 깊이를 더해줄 수 있습니다. 좀 더 미묘한 페어링을 원하신다면 피노 누아의 가벼운 바디와 밝은 산미가 풍부함을 줄이고 우아함을 더해줄 수 있습니다. 이러한 와인은 각각 고유한 보완을 제공하여 솔즈베리 스테이크 경험을 향상시키는 데 이상적인 선택입니다.\\n카베르네 소비뇽 [...] 카베르네 소비뇽은 진한 과일 맛과 고소한 풍미로 유명한 풀바디 와인으로 솔즈베리 스테이크의 풍부한 맛을 보완하기에 완벽합니다. 카베르네 소비뇽의 타닌은 스테이크의 식감을 향상시켜 한 입 먹을 때마다 더욱 즐거운 경험을 선사합니다.\\n메를로\\n부드러운 타닌과 벨벳 같은 마무리감이 특징인 메를로는 솔즈베리 스테이크와 환상적인 조화를 이룹니다. 부드러운 질감과 자두, 초콜릿의 힌트가 고소한 소고기 패티와 조화로운 균형을 이룹니다.\\n화이트 와인을 곁들인 솔즈베리 스테이크\\n레드 와인이 인기가 많지만 화이트 와인도 솔즈베리 스테이크와 잘 어울리며, 특히 가벼운 와인을 선호하는 분들에게는 흥미로운 페어링이 될 수 있습니다.\\n샤르도네\\n샤르도네는 버터와 크리미한 향을 내는 다용도 와인으로 버섯 그레이비를 곁들인 솔즈베리 스테이크와 잘 어울립니다. 와인의 산미가 요리의 풍성함과 균형을 잡아주고 상큼한 대비를 더해줍니다.\\n더 많은 화이트 와인 옵션'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "b6791575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T04:03:40.277819Z",
     "start_time": "2025-03-27T04:03:40.264597Z"
    }
   },
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(web_search))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(web_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(web_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(web_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자료형: \n",
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "tavily_search_results_json\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "('A search engine optimized for comprehensive, accurate, and trusted results. '\n",
      " 'Useful for when you need to answer questions about current events. Input '\n",
      " 'should be a search query.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Input for the Tavily tool.',\n",
      " 'properties': {'query': {'description': 'search query to look up',\n",
      "                          'title': 'Query',\n",
      "                          'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'TavilyInput',\n",
      " 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "88b600d9",
   "metadata": {},
   "source": [
    "`(2) 도구(tool) 호출하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "51a3633c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T05:26:10.827193Z",
     "start_time": "2025-04-11T05:26:05.288251Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 웹 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=[web_search])"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "17d2468d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T05:31:45.068723Z",
     "start_time": "2025-04-11T05:31:41.107752Z"
    }
   },
   "source": [
    "# 도구 호출이 필요 없는 LLM 호출을 수행\n",
    "query = \"안녕하세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='안녕하세요! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 82, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_44added55e', 'finish_reason': 'stop', 'logprobs': None}, id='run-81565a18-1611-4059-b1fe-92a99d4afc7f-0', usage_metadata={'input_tokens': 82, 'output_tokens': 12, 'total_tokens': 94})\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'안녕하세요! 어떻게 도와드릴까요?'\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "dd8df009",
   "metadata": {},
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "84d0d45d",
   "metadata": {},
   "source": [
    "tool_call = ai_msg.tool_calls[0]\n",
    "tool_call"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "86835305",
   "metadata": {},
   "source": [
    "`(3) 도구(tool) 실행하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3eb0c7e",
   "metadata": {},
   "source": [
    "### 방법 1: 직접 도구 호출 처리\n",
    "\n",
    "# 이 방법은 AI 메시지에서 첫 번째 도구 호출을 가져와 직접 처리한다.\n",
    "# 'args'를 사용하여 도구를 호출하고 결과를 얻는다.\n",
    "\n",
    "tool_output = web_search.invoke(tool_call[\"args\"])\n",
    "print(f\"{tool_call['name']} 호출 결과:\")\n",
    "print(\"-\" * 100)\n",
    "print(tool_output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1fa17109",
   "metadata": {},
   "source": [
    "### 방법 2: ToolMessage 객체 생성\n",
    "\n",
    "# 이 방법은 도구 호출 결과를 사용하여 ToolMessage 객체를 생성한다.\n",
    "# 도구 호출의 ID와 이름을 포함하여 더 구조화된 메시지를 만든다.\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "tool_message = ToolMessage(\n",
    "    content=tool_output,\n",
    "    tool_call_id=tool_call[\"id\"],\n",
    "    name=tool_call[\"name\"]\n",
    ")\n",
    "\n",
    "print(tool_message)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0f39f32b",
   "metadata": {},
   "source": [
    "### 방법 3: 도구 직접 호출하여 바로 ToolMessage 객체 생성\n",
    "\n",
    "# 이 방법은 도구를 직접 호출하여 ToolMessage 객체를 생성한다.\n",
    "# 가장 간단하고 직관적인 방법으로, LangChain의 추상화를 활용한다.\n",
    "\n",
    "tool_message = web_search.invoke(tool_call)\n",
    "\n",
    "print(tool_message)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aeeb5890",
   "metadata": {},
   "source": [
    "pprint(tool_message.tool_call_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "01309400",
   "metadata": {},
   "source": [
    "pprint(tool_message.name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82d9a51c",
   "metadata": {},
   "source": [
    "pprint(tool_message.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3e71c37",
   "metadata": {},
   "source": [
    "ai_msg.tool_calls"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35a3ad18",
   "metadata": {},
   "source": [
    "# batch 실행 - 도구 호출이 여러 개인 경우\n",
    "\n",
    "# tool_messages = web_search.batch([tool_call])\n",
    "\n",
    "tool_messages = web_search.batch(ai_msg.tool_calls)\n",
    "\n",
    "print(tool_messages)\n",
    "print(\"-\" * 100)\n",
    "pprint(tool_messages[0].content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a20257ba",
   "metadata": {},
   "source": [
    "`(4) ToolMessage를 LLM에 전달하여 답변을 생성하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c5de654",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[web_search])\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def web_search_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "    tool_msgs = web_search.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "response = web_search_chain.invoke(\"오늘 모엣샹동 샴페인의 가격은 얼마인가요?\")\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "60f49a9f",
   "metadata": {},
   "source": [
    "### 2-2. 사용자 정의 도구\n",
    "- @tool decorator를 통해 사용자 정의 도구를 정의할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c058ff5",
   "metadata": {},
   "source": [
    "`(1) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "2647393d",
   "metadata": {},
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "\n",
    "# Tool 정의 \n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Searches the internet for information that does not exist in the database or for the latest information.\"\"\"\n",
    "\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "\n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "        ])\n",
    "\n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "224eddd8",
   "metadata": {},
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(search_web))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_web.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_web.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_web.args_schema.schema())\n",
    "print(\"-\"*100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "37117ba5",
   "metadata": {},
   "source": [
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "search_result = search_web.invoke(query)\n",
    "\n",
    "print(search_result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d81d6668",
   "metadata": {},
   "source": [
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[search_web])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7dcda933",
   "metadata": {},
   "source": [
    "`(2) LLM 도구 호출 성능 비교하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "edf539df",
   "metadata": {},
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# 기본 LLM\n",
    "llm_gemini_flash = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "llm_gemini_pro = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n",
    "llm_groq = ChatGroq(model=\"llama3-groq-70b-8192-tool-use-preview\", temperature=0)\n",
    "\n",
    "# LLM에 도구 바인딩하여 추가 \n",
    "tools=[search_web]\n",
    "\n",
    "gemini_flash_with_tools = llm_gemini_flash.bind_tools(tools)\n",
    "gemini_pro_with_tools = llm_gemini_pro.bind_tools(tools)\n",
    "groq_llama3_with_tools = llm_groq.bind_tools(tools)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc7f29ab",
   "metadata": {},
   "source": [
    "- gemini-1.5-flash"
   ]
  },
  {
   "cell_type": "code",
   "id": "faceb0af",
   "metadata": {},
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = gemini_flash_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6f69b933",
   "metadata": {},
   "source": [
    "- gemini-1.5-pro"
   ]
  },
  {
   "cell_type": "code",
   "id": "b93b3cf2",
   "metadata": {},
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = gemini_pro_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "500d19ee",
   "metadata": {},
   "source": [
    "- llama3-groq-70b-8192-tool-use-preview"
   ]
  },
  {
   "cell_type": "code",
   "id": "36366e87",
   "metadata": {},
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = groq_llama3_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7b2d5144",
   "metadata": {},
   "source": [
    "### 2-3. Runnable 객체를 도구(tool) 변환\n",
    "- 문자열이나 dict 입력을 받는 Runnable을 도구로 변환\n",
    "- as_tool 메서드를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea96cf",
   "metadata": {},
   "source": [
    "`(1) Document Loader`"
   ]
  },
  {
   "cell_type": "code",
   "id": "933f7aa5",
   "metadata": {},
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# WikipediaLoader를 사용하여 위키피디아 문서를 검색하는 함수 \n",
    "def search_wiki(input_data: dict) -> List[Document]:\n",
    "    \"\"\"Search Wikipedia documents based on user input (query) and return k documents\"\"\"\n",
    "    query = input_data[\"query\"]\n",
    "    k = input_data.get(\"k\", 2)  \n",
    "    wiki_loader = WikipediaLoader(query=query, load_max_docs=k, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "    return wiki_docs\n",
    "\n",
    "# 도구 호출에 사용할 입력 스키마 정의 \n",
    "class WikiSearchSchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "    k: int = Field(2, description=\"The number of documents to return (default is 2)\")\n",
    "\n",
    "# RunnableLambda 함수를 사용하여 위키피디아 문서 로더를 Runnable로 변환 \n",
    "runnable = RunnableLambda(search_wiki)\n",
    "wiki_search = runnable.as_tool(\n",
    "    name=\"wiki_search\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a specified number of documents. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSearchSchema\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff26347a",
   "metadata": {},
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(wiki_search))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed7ff3c4",
   "metadata": {},
   "source": [
    "# 위키 검색 실행\n",
    "query = \"파스타의 유래\"\n",
    "wiki_results = wiki_search.invoke({\"query\":query})\n",
    "\n",
    "# 검색 결과 출력\n",
    "for result in wiki_results:\n",
    "    print(result)  \n",
    "    print(\"-\" * 100)  "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1b812a0a",
   "metadata": {},
   "source": [
    "# LLM에 도구를 바인딩 (2개의 도구 바인딩)\n",
    "llm_with_tools = llm.bind_tools(tools=[search_web, wiki_search])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"서울 강남의 유명한 파스타 맛집은 어디인가요? 그리고 파스타의 유래를 알려주세요. \"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "db06d2ed",
   "metadata": {},
   "source": [
    "`(2) LCEL 체인`\n",
    "- 위키피디아 문서를 검색하고 내용을 요약하는 체인"
   ]
  },
  {
   "cell_type": "code",
   "id": "4a7ab14a",
   "metadata": {},
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "# WikipediaLoader를 사용하여 위키피디아 문서를 검색하고 텍스트로 반환하는 함수 \n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query=input_data[\"query\"], load_max_docs=2, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "\n",
    "    formatted_docs =[\n",
    "        f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in wiki_docs\n",
    "        ]\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "# 요약 프롬프트 템플릿\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner:\\n\\n{context}\\n\\nSummary:\"\n",
    ")\n",
    "\n",
    "# LLM 및 요약 체인 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)}\n",
    "    | summary_prompt | llm | StrOutputParser() \n",
    ")\n",
    "\n",
    "# 요약 테스트 \n",
    "summarized_text = summary_chain.invoke({\"query\":\"파스타의 유래\"})\n",
    "pprint(summarized_text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a35ac080",
   "metadata": {},
   "source": [
    "# 도구 호출에 사용할 입력 스키마 정의 \n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "\n",
    "# as_tool 메소드를 사용하여 도구 객체로 변환\n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name=\"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSummarySchema\n",
    ")\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(wiki_summary))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_summary.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_summary.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_summary.args_schema.schema())\n",
    "print(\"-\"*100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "78824759",
   "metadata": {},
   "source": [
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[search_web, wiki_summary])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"서울 강남의 유명한 파스타 맛집은 어디인가요? 그리고 파스타의 유래를 알려주세요. \"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c87d0b1a",
   "metadata": {},
   "source": [
    "ai_msg.tool_calls[1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "12cbdd5c",
   "metadata": {},
   "source": [
    "# 도구 실행 \n",
    "tool_message = wiki_summary.invoke(ai_msg.tool_calls[1])\n",
    "\n",
    "print(tool_message)\n",
    "print(\"-\" * 100)\n",
    "pprint(tool_message.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e2de1a6",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[wiki_summary])\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def wiki_summary_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "    tool_msgs = wiki_summary.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "response = wiki_summary_chain.invoke(\"파스타의 유래에 대해서 알려주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6f828547",
   "metadata": {},
   "source": [
    "### 2-4. 벡터저장소 검색기\n",
    "- @tool decorator 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9dc12",
   "metadata": {},
   "source": [
    "`(1) 문서 로드 및 인덱싱`"
   ]
  },
  {
   "cell_type": "code",
   "id": "a0da1d76",
   "metadata": {},
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# 메뉴판 텍스트 데이터를 로드\n",
    "loader = TextLoader(\"./data/restaurant_menu.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(len(documents))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5e94154e",
   "metadata": {},
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# 문서 분할 (Chunking)\n",
    "def split_menu_items(document):\n",
    "    \"\"\"\n",
    "    메뉴 항목을 분리하는 함수 \n",
    "    \"\"\"\n",
    "    # 정규표현식 정의 \n",
    "    pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "    menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "    \n",
    "    # 각 메뉴 항목을 Document 객체로 변환\n",
    "    menu_documents = []\n",
    "    for i, item in enumerate(menu_items, 1):\n",
    "        # 메뉴 이름 추출\n",
    "        menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "        \n",
    "        # 새로운 Document 객체 생성\n",
    "        menu_doc = Document(\n",
    "            page_content=item.strip(),\n",
    "            metadata={\n",
    "                \"source\": document.metadata['source'],\n",
    "                \"menu_number\": i,\n",
    "                \"menu_name\": menu_name\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "    \n",
    "    return menu_documents\n",
    "\n",
    "\n",
    "# 메뉴 항목 분리 실행\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"총 {len(menu_documents)}개의 메뉴 항목이 처리되었습니다.\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8552797f",
   "metadata": {},
   "source": [
    "# Chroma Vectorstore를 사용하기 위한 준비\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama  import OllamaEmbeddings\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(model=\"bge-m3\") \n",
    "\n",
    "# Chroma 인덱스 생성\n",
    "menu_db = Chroma.from_documents(\n",
    "    documents=menu_documents, \n",
    "    embedding=embeddings_model,   \n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "# Retriever 생성\n",
    "menu_retriever = menu_db.as_retriever(\n",
    "    search_kwargs={'k': 2},\n",
    ")\n",
    "\n",
    "# 쿼리 테스트\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요?\"\n",
    "docs = menu_retriever.invoke(query)\n",
    "print(f\"검색 결과: {len(docs)}개\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9cf58d36",
   "metadata": {},
   "source": [
    "- 와인 메뉴에 대해서도 같은 작업을 처리"
   ]
  },
  {
   "cell_type": "code",
   "id": "1dc82b06",
   "metadata": {},
   "source": [
    "# 와인 메뉴 텍스트 데이터를 로드\n",
    "loader = TextLoader(\"./data/restaurant_wine.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 메뉴 항목 분리 실행\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"총 {len(menu_documents)}개의 메뉴 항목이 처리되었습니다.\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")\n",
    "\n",
    "\n",
    "# Chroma 인덱스 생성\n",
    "wine_db = Chroma.from_documents(\n",
    "    documents=menu_documents, \n",
    "    embedding=embeddings_model,   \n",
    "    collection_name=\"restaurant_wine\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "wine_retriever = wine_db.as_retriever(\n",
    "    search_kwargs={'k': 2},\n",
    ")\n",
    "\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "docs = wine_retriever.invoke(query)\n",
    "print(f\"검색 결과: {len(docs)}개\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2040915b",
   "metadata": {},
   "source": [
    "`(2) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "93d4c3a5",
   "metadata": {},
   "source": [
    "# 벡터 저장소 로드\n",
    "menu_db = Chroma(\n",
    "    embedding_function=embeddings_model,   \n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_menu(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant menu information from the encrypted database.\n",
    "    Use this tool only for menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = menu_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 메뉴 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(search_menu))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_menu.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_menu.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_menu.args_schema.schema())\n",
    "print(\"-\"*100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8ae1341",
   "metadata": {},
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 벡터 저장소 로드\n",
    "wine_db = Chroma(\n",
    "   embedding_function=embeddings_model,   \n",
    "   collection_name=\"restaurant_wine\",\n",
    "   persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_wine(query: str) -> List[Document]:\n",
    "   \"\"\"\n",
    "   Securely retrieve and access authorized restaurant wine information from the encrypted database.\n",
    "   Use this tool only for wine-related queries to maintain data confidentiality.\n",
    "   \"\"\"\n",
    "   docs = wine_db.similarity_search(query, k=2)\n",
    "   if len(docs) > 0:\n",
    "      return docs\n",
    "   \n",
    "   return [Document(page_content=\"관련 와인 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(search_wine))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_wine.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_wine.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_wine.args_schema.schema())\n",
    "print(\"-\"*100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51ac56a5",
   "metadata": {},
   "source": [
    "# LLM에 도구를 바인딩 (2개의 도구 바인딩)\n",
    "llm_with_tools = llm.bind_tools(tools=[search_menu, search_wine])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7f7b74a1",
   "metadata": {},
   "source": [
    "`(3) 여러 개의 도구(tool) 호출하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "23c3bba9",
   "metadata": {},
   "source": [
    "tools = [search_web, wiki_summary, search_wine, search_menu]\n",
    "for tool in tools:\n",
    "    print(tool.name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1eda10de",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 4개의 검색 도구를 LLM에 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def restaurant_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        if tool_call[\"name\"] == \"search_web\":\n",
    "            tool_message = search_web.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_wine\":\n",
    "            tool_message = search_wine.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_menu\":\n",
    "            tool_message = search_menu.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)            \n",
    "\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "response = restaurant_menu_chain.invoke(\"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f93b3215",
   "metadata": {},
   "source": [
    "# 체인 실행\n",
    "response = restaurant_menu_chain.invoke(\"파스타 메뉴가 있나요? 이 음식의 역사 또는 유래를 알려주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc3b78e3",
   "metadata": {},
   "source": [
    "## 3. Few-shot 프롬프팅 \n",
    "- 각 도구의 용도를 구분하여 few-shot 예제로 제시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3e6b9",
   "metadata": {},
   "source": [
    "### 3-1. Few-shot 도구 호출"
   ]
  },
  {
   "cell_type": "code",
   "id": "5fd743c1",
   "metadata": {},
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\"트러플 리조또의 가격과 특징, 그리고 어울리는 와인에 대해 알려주세요.\", name=\"example_user\"),\n",
    "    AIMessage(\"메뉴 정보를 검색하고, 위키피디아에서 추가 정보를 찾은 후, 어울리는 와인을 검색해보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"search_menu\", \"args\": {\"query\": \"트러플 리조또\"}, \"id\": \"1\"}]),\n",
    "    ToolMessage(\"트러플 리조또: 가격 ₩28,000, 이탈리아 카나롤리 쌀 사용, 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리\", tool_call_id=\"1\"),\n",
    "    AIMessage(\"트러플 리조또의 가격은 ₩28,000이며, 이탈리아 카나롤리 쌀을 사용하고 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리합니다. 이제 추가 정보를 위키피디아에서 찾아보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"wiki_summary\", \"args\": {\"query\": \"트러플 리조또\", \"k\": 1}, \"id\": \"2\"}]),\n",
    "    ToolMessage(\"트러플 리조또는 이탈리아 요리의 대표적인 리조또 요리 중 하나로, 고급 식재료인 트러플을 사용하여 만든 크리미한 쌀 요리입니다. 주로 아르보리오나 카나롤리 등의 쌀을 사용하며, 트러플 오일이나 생 트러플을 넣어 조리합니다. 리조또 특유의 크리미한 질감과 트러플의 강렬하고 독특한 향이 조화를 이루는 것이 특징입니다.\", tool_call_id=\"2\"),\n",
    "    AIMessage(\"트러플 리조또의 특징에 대해 알아보았습니다. 이제 어울리는 와인을 검색해보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"search_wine\", \"args\": {\"query\": \"트러플 리조또에 어울리는 와인\"}, \"id\": \"3\"}]),\n",
    "    ToolMessage(\"트러플 리조또와 잘 어울리는 와인으로는 주로 중간 바디의 화이트 와인이 추천됩니다. 1. 샤르도네: 버터와 오크향이 트러플의 풍미를 보완합니다. 2. 피노 그리지오: 산뜻한 산미가 리조또의 크리미함과 균형을 이룹니다. 3. 베르나차: 이탈리아 토스카나 지방의 화이트 와인으로, 미네랄리티가 트러플과 잘 어울립니다.\", tool_call_id=\"3\"),\n",
    "    AIMessage(\"트러플 리조또(₩28,000)는 이탈리아의 대표적인 리조또 요리 중 하나로, 이탈리아 카나롤리 쌀을 사용하고 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리합니다. 주요 특징으로는 크리미한 질감과 트러플의 강렬하고 독특한 향이 조화를 이루는 점입니다. 고급 식재료인 트러플을 사용해 풍부한 맛과 향을 내며, 주로 아르보리오나 카나롤리 등의 쌀을 사용합니다. 트러플 리조또와 잘 어울리는 와인으로는 중간 바디의 화이트 와인이 추천됩니다. 특히 버터와 오크향이 트러플의 풍미를 보완하는 샤르도네, 산뜻한 산미로 리조또의 크리미함과 균형을 이루는 피노 그리지오, 그리고 미네랄리티가 트러플과 잘 어울리는 이탈리아 토스카나 지방의 베르나차 등이 좋은 선택이 될 수 있습니다.\", name=\"example_assistant\"),\n",
    "]\n",
    "\n",
    "system = \"\"\"You are an AI assistant providing restaurant menu information and general food-related knowledge.\n",
    "For information about the restaurant's menu, use the search_menu tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "For wine recommendations or pairing information, use the search_wine tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    *examples,\n",
    "    (\"human\", \"{query}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# Few-shot 프롬프트를 사용한 체인 구성\n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools\n",
    "\n",
    "# 체인 실행\n",
    "query = \"스테이크 메뉴가 있나요? 스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "response = fewshot_search_chain.invoke(query)\n",
    "\n",
    "# 결과 출력\n",
    "for tool_call in response.tool_calls:\n",
    "    print(tool_call)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c442be3f",
   "metadata": {},
   "source": [
    "# 체인 실행\n",
    "query = \"파스타의 유래에 대해서 알고 있나요? 서울 강남의 파스타 맛집을 추천해주세요.\"\n",
    "response = fewshot_search_chain.invoke(query)\n",
    "\n",
    "# 결과 출력\n",
    "for tool_call in response.tool_calls:\n",
    "    print(tool_call)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a2f10c84",
   "metadata": {},
   "source": [
    "### 3-2. 답변 생성 체인 "
   ]
  },
  {
   "cell_type": "code",
   "id": "49a4d3c7",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "system = \"\"\"You are an AI assistant providing restaurant menu information and general food-related knowledge.\n",
    "For information about the restaurant's menu, use the search_menu tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "For wine recommendations or pairing information, use the search_wine tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system + f\"Today's date is {today}.\"),\n",
    "    *examples,\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# Few-shot 프롬프트를 사용한 체인 구성\n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def restaurant_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        if tool_call[\"name\"] == \"search_web\":\n",
    "            tool_message = search_web.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_wine\":\n",
    "            tool_message = search_wine.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_menu\":\n",
    "            tool_message = search_menu.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)            \n",
    "\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return fewshot_search_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "\n",
    "# 체인 실행\n",
    "query = \"스테이크 메뉴가 있나요? 스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d60b9ebc",
   "metadata": {},
   "source": [
    "# 체인 실행\n",
    "query = \"파스타의 유래에 대해서 알고 있나요? 서울 강남의 파스타 맛집을 추천해주세요.\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "11927ed4",
   "metadata": {},
   "source": [
    "## 4. LangChain Agent 사용\n",
    "- 유의사항: 프롬프트에 \"agent_scratchpad\",  \"input\" 변수를 포함"
   ]
  },
  {
   "cell_type": "code",
   "id": "7127af7a",
   "metadata": {},
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", dedent(\"\"\"\n",
    "        You are an AI assistant providing restaurant menu information and general food-related knowledge. \n",
    "        Your main goal is to provide accurate information and effective recommendations to users.\n",
    "\n",
    "        Key guidelines:\n",
    "        1. For restaurant menu information, use the search_menu tool. This tool provides details on menu items, including prices, ingredients, and cooking methods.\n",
    "        2. For general food information, history, and cultural background, utilize the wiki_summary tool.\n",
    "        3. For wine recommendations or food and wine pairing information, use the search_wine tool.\n",
    "        4. If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "        5. Provide clear and concise responses based on the search results.\n",
    "        6. If a question is ambiguous or lacks necessary information, politely ask for clarification.\n",
    "        7. Always maintain a helpful and professional tone.\n",
    "        8. When providing menu information, describe in the order of price, main ingredients, and distinctive cooking methods.\n",
    "        9. When making recommendations, briefly explain the reasons.\n",
    "        10. Maintain a conversational, chatbot-like style in your final responses. Be friendly, engaging, and natural in your communication.\n",
    "\n",
    "\n",
    "        Remember, understand the purpose of each tool accurately and use them in appropriate situations. \n",
    "        Combine the tools to provide the most comprehensive and accurate answers to user queries. \n",
    "        Always strive to provide the most current and accurate information.\n",
    "        \"\"\")),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b3dad12e",
   "metadata": {},
   "source": [
    "# Tool calling Agent 생성\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "tools = [search_web, wiki_summary, search_wine, search_menu]\n",
    "agent = create_tool_calling_agent(llm, tools, agent_prompt)\n",
    "\n",
    "# AgentExecutor 생성 \n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6cd37cf1",
   "metadata": {},
   "source": [
    "# AgentExecutor 실행\n",
    "\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\"\n",
    "agent_response = agent_executor.invoke({\"input\": query})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bdef9044",
   "metadata": {},
   "source": [
    "pprint(agent_response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eb411fca",
   "metadata": {},
   "source": [
    "## 5. Gradio 활용"
   ]
  },
  {
   "cell_type": "code",
   "id": "56abbad7",
   "metadata": {},
   "source": [
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "\n",
    "def answer_invoke(message: str, history: List[Tuple[str, str]]) -> str:\n",
    "    try:\n",
    "        # 채팅 기록을 AI에게 전달할 수 있는 형식으로 변환\n",
    "        chat_history = []\n",
    "        for human, ai in history:\n",
    "            chat_history.append(HumanMessage(content=human))\n",
    "            chat_history.append(AIMessage(content=ai))\n",
    "        \n",
    "        # agent_executor를 사용하여 응답 생성\n",
    "        response = agent_executor.invoke({\n",
    "            \"input\": message,\n",
    "            \"chat_history\": chat_history[-2:]    # 최근 2개의 메시지 기록만을 활용 \n",
    "        })\n",
    "        \n",
    "        # agent_executor의 응답에서 최종 답변 추출\n",
    "        return response['output']\n",
    "    except Exception as e:\n",
    "        # 오류 발생 시 사용자에게 알리고 로그 기록\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return \"죄송합니다. 응답을 생성하는 동안 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "# 예제 질문 정의\n",
    "example_questions = [\n",
    "    \"시그니처 스테이크의 가격과 특징을 알려주세요.\",\n",
    "    \"트러플 리조또와 잘 어울리는 와인을 추천해주세요.\",\n",
    "    \"해산물 파스타의 주요 재료는 무엇인가요? 서울 강남 지역에 레스토랑을 추천해주세요.\",\n",
    "    \"채식주의자를 위한 메뉴 옵션이 있나요?\"\n",
    "]\n",
    "\n",
    "# Gradio 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,\n",
    "    title=\"레스토랑 메뉴 AI 어시스턴트\",\n",
    "    description=\"메뉴 정보, 추천, 음식 관련 질문에 답변해 드립니다.\",\n",
    "    examples=example_questions,\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "# 데모 실행\n",
    "demo.launch()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1bd26485",
   "metadata": {},
   "source": [
    "# 데모 종료\n",
    "demo.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9fb837bc",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-agent-fZJ3tIVY-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
