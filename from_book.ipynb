{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-22T01:21:57.387938Z",
     "start_time": "2025-04-22T01:21:57.312439Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:24:49.810938Z",
     "start_time": "2025-04-22T01:24:49.793877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import os, json\n",
    "from glob import glob\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import uuid\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "c6a089fb5fe7ee22",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```Let’s look at an example of registering a calculator skill. First, we define our simple calculator function:```",
   "id": "15a9d47c36eadf28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T02:46:05.138858Z",
     "start_time": "2025-04-22T02:46:03.785748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# # 기본 LLM\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, streaming=True)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.getenv('AZURE_OPENAI_VERSION')\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv('AZURE_OPENAI_END_POINT')\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv('AZURE_OPENAI_KEY')\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.getenv('DEPLOYMENT_NAME'),  # or your deployment\n",
    "    api_version=os.getenv('AZURE_OPENAI_VERSION'),  # or your api version\n",
    "    temperature=0,\n",
    "    # stream=True,\n",
    "    # max_tokens=40000,\n",
    "    # timeout=None,\n",
    "    # max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# \n",
    "# # claude 모델 로드 \n",
    "# llm = ChatAnthropic(\n",
    "#     # model=\"claude-3-5-sonnet-20241022\",\n",
    "#     model=\"claude-3-7-sonnet-20250219\",\n",
    "#     temperature=0,\n",
    "#     # max_tokens=200, \n",
    "#     api_key=os.getenv('ANTHROPIC_API_KEY'),\n",
    "#     streaming=True,\n",
    "# )\n",
    "\n"
   ],
   "id": "4c5694c93bf6d9d7",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T07:39:14.898133Z",
     "start_time": "2025-04-21T07:39:07.949573Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    " \n",
    "# Define tools using concise function definitions\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "   \"\"\"Multiply 'x' times 'y'.\"\"\"\n",
    "   return x * y\n",
    " \n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "   \"\"\"Raise 'x' to the 'y'.\"\"\"\n",
    "   return x**y\n",
    " \n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "   \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "   return x + y"
   ],
   "id": "11ca882b0c5fbe09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T07:39:24.800369Z",
     "start_time": "2025-04-21T07:39:24.794815Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "tools = [multiply, exponentiate, add]\n",
    "\n",
    "# LLM에 도구 바인딩하여 추가 \n",
    "llm_with_tools = llm.bind_tools(tools)"
   ],
   "id": "5fb2c7e4ea3775a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```register it here as an LLM with tools class from LangChain.```  ",
   "id": "854ed5789cb11e66"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T07:41:45.855258Z",
     "start_time": "2025-04-21T07:41:45.841146Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain_core.messages import HumanMessage",
   "id": "ec2841dc1c9d6998",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T07:41:47.546775Z",
     "start_time": "2025-04-21T07:41:47.541244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What is 393 * 12.25? Also, what is 11 + 49?\"\n",
    "messages = [HumanMessage(query)]"
   ],
   "id": "3be11b9326ff055",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```Now that we’ve bound the tool, we can ask the LLM questions, and if the tool is helpful for answering the question, the LLM will choose the tools, select the parameters for those tools, and invoke those functions.```",
   "id": "5df1c876107d1415"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T07:42:15.348940Z",
     "start_time": "2025-04-21T07:42:13.874743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n"
   ],
   "id": "e94e9fe54ddcf864",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```With those added print statements for visibility, we can see that the LLM invokes two function calls: one each for multiple and add.```",
   "id": "e053827a9d2d84e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T07:59:17.044833Z",
     "start_time": "2025-04-21T07:59:17.031614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    #키는 \"add\", \"multiply\", \"exponentiate\"이며, 각각의 키에 대해 대응 되는 함수( add, multiply, exponentiate)를 값으로 가짐\n",
    "    #예를 들어, tool_call[\"name\"]가 \"add\"였으면, dictionary 에서 \"add\" 키와 일치 하는 값을 가져옴(여기서 add or  multiply 함수).\n",
    "    # 이렇게 가져온 함수는 selected_tool 변수에 저장\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply, \"exponentiate\": exponentiate}[tool_call[\"name\"].lower()]\n",
    "    # 선택된 도구를 invoke 하면서 tool_call input 으로 입력함.\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    print(f\"{tool_msg.name} {tool_call['args']} {tool_msg.content}\")\n",
    "    # tool Message 객체의 응답 데이터 append 됨\n",
    "    messages.append(tool_msg)"
   ],
   "id": "345be396040cab2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply {'x': 393, 'y': 12.25} 4814.25\n",
      "add {'x': 11, 'y': 49} 60.0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```then considers the output from both when composing the final response.```",
   "id": "3de4da8682d14a78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T08:06:21.672753Z",
     "start_time": "2025-04-21T08:06:20.344283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_response = llm_with_tools.invoke(messages)\n",
    "print(final_response.content)"
   ],
   "id": "3fb2add5ac904a7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of \\(393 \\times 12.25\\) is 4814.25, and the result of \\(11 + 49\\) is 60.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "``you want to enable your agent to browse the open web for additional information. Doing so is as simple as registering a web surfing agent:``",
   "id": "a99ef0a586a6d6dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T08:10:17.409075Z",
     "start_time": "2025-04-21T08:10:15.673813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.messages import HumanMessage\n",
    " \n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=2, doc_content_chars_max=300)\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    " \n",
    "# Initialize the LLM with GPT-4o and bind the tools\n",
    "# llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools([tool])\n",
    " \n",
    "# messages = [HumanMessage(\"What was the most impressive thing about Buzz Aldrin?\")]\n",
    "messages = [HumanMessage(\"What was the most impressive thing about maria callas?\")]\n",
    " \n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n"
   ],
   "id": "258fa06bebce0f72",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "``` LLM identifies the object of interest in the query, and searches Wikipedia for the term. It then uses this additional information to generate its final answer when addressing the question.```",
   "id": "49b9677d512746b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T08:13:54.812452Z",
     "start_time": "2025-04-21T08:13:50.753891Z"
    }
   },
   "cell_type": "code",
   "source": [
    " \n",
    "for tool_call in ai_msg.tool_calls:\n",
    "   tool_msg = tool.invoke(tool_call)\n",
    "  \n",
    "   print(tool_msg.name)\n",
    "   print(tool_call['args'])\n",
    "   print(tool_msg.content)\n",
    "   messages.append(tool_msg)\n",
    "   # print()\n"
   ],
   "id": "634e8f2a2640cc5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n",
      "{'query': 'Maria Callas'}\n",
      "Page: Maria Callas\n",
      "Summary: Maria Callas  (born Maria Anna Cecilia Sophia Kalogeropoulos; December 2, 1923 – September 16, 1977) was an American-born Greek soprano and one of the most renowned and influential opera singers of the 20th century. Many critics praised her bel canto technique, wide-rangi\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T08:15:33.064093Z",
     "start_time": "2025-04-21T08:15:31.606929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_response = llm_with_tools.invoke(messages)\n",
    "print(final_response.content)"
   ],
   "id": "cf1b34b2b5fe7937",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maria Callas was renowned for her exceptional bel canto technique and wide-ranging voice, which made her one of the most influential opera singers of the 20th century. Her ability to convey deep emotion and her dramatic presence on stage were also highly impressive, contributing to her lasting legacy in the world of opera.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 스킬 설계 고려사항\n",
    "```\n",
    "효과적인 스킬을 설계하기 위해서는 몇 가지 주요 고려사항이 필요합니다:\n",
    "일반화 vs. 특수화\n",
    "스킬은 특정 작업에 대해 매우 특화되어 설계되거나, 여러 관련 작업을 처리할 수 있도록 일반화되어 설계될 수 있습니다. 일반화와 특수화의 선택은 AI 에이전트의 의도된 사용 사례와 원하는 유연성에 따라 달라집니다.\n",
    "견고성\n",
    "스킬은 입력의 변동성과 예기치 않은 시나리오를 처리할 수 있을 만큼 견고해야 합니다. 이를 위해서는 현실 세계의 응용에서 신뢰성을 보장하기 위한 철저한 테스트와 개선 과정이 필요합니다.\n",
    "효율성\n",
    "효율적인 스킬은 컴퓨팅 자원과 실행 시간을 최소화하여 AI 에이전트의 전반적인 성능을 향상시킵니다. 알고리즘 개선 및 하드웨어 가속과 같은 최적화 기법은 효율성 달성에 중요한 역할을 합니다.\n",
    "확장성\n",
    "작업의 복잡성이 증가함에 따라, 스킬도 원활하게 확장되어야 합니다. 이는 더 정교한 문제에 대처하기 위해 쉽게 확장되거나 다른 스킬과 결합될 수 있도록 설계하는 것을 포함합니다."
   ],
   "id": "7625c43bf040fc6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "define the function that interacts with the stock market API. Then, we register this function as a skill for our agent, and we can then invoke it just like the previous skills."
   ],
   "id": "dd593588bce897ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T08:32:28.042545Z",
     "start_time": "2025-04-21T08:32:28.021589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.messages import HumanMessage\n",
    "import requests\n",
    " \n",
    "@tool\n",
    "def get_stock_price(ticker: str) -> float:\n",
    "   \"\"\"Get the stock price for the stock exchange ticker for the company.\"\"\"\n",
    "   api_url = f\"https://api.example.com/stocks/{ticker}\"\n",
    "   response = requests.get(api_url)\n",
    "   if response.status_code == 200:\n",
    "       data = response.json()\n",
    "       return data[\"price\"]\n",
    "   else:\n",
    "       raise ValueError(f\"Failed to fetch stock price for {ticker}\")\n",
    " \n",
    " \n",
    "# Initialize the LLM with GPT-4o and bind the tools\n",
    "# llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools([get_stock_price])\n"
   ],
   "id": "4c1eab44f5e00797",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T08:32:57.165706Z",
     "start_time": "2025-04-21T08:32:56.135232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = [HumanMessage(\"What is the stock price of Apple?\")]\n",
    " \n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)"
   ],
   "id": "277014fb1c5bb513",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T08:33:56.155249Z",
     "start_time": "2025-04-21T08:33:54.909638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "   tool_msg = get_stock_price.invoke(tool_call)\n",
    "  \n",
    "   print(tool_msg.name)\n",
    "   print(tool_call['args'])\n",
    "   print(tool_msg.content)\n",
    "   messages.append(tool_msg)\n",
    "   print()\n",
    " \n",
    "final_response = llm_with_tools.invoke(messages)\n",
    "print(final_response.content)"
   ],
   "id": "a6fdbe773f810d6a",
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /stocks/AAPL (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E225DBF7D0>: Failed to resolve 'api.example.com' ([Errno 11001] getaddrinfo failed)\"))",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mgaierror\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\urllib3\\connection.py:198\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 198\u001B[0m     sock \u001B[38;5;241m=\u001B[39m connection\u001B[38;5;241m.\u001B[39mcreate_connection(\n\u001B[0;32m    199\u001B[0m         (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dns_host, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mport),\n\u001B[0;32m    200\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout,\n\u001B[0;32m    201\u001B[0m         source_address\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_address,\n\u001B[0;32m    202\u001B[0m         socket_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket_options,\n\u001B[0;32m    203\u001B[0m     )\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m socket\u001B[38;5;241m.\u001B[39mgaierror \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\urllib3\\util\\connection.py:60\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LocationParseError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhost\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, label empty or too long\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m socket\u001B[38;5;241m.\u001B[39mgetaddrinfo(host, port, family, socket\u001B[38;5;241m.\u001B[39mSOCK_STREAM):\n\u001B[0;32m     61\u001B[0m     af, socktype, proto, canonname, sa \u001B[38;5;241m=\u001B[39m res\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\socket.py:974\u001B[0m, in \u001B[0;36mgetaddrinfo\u001B[1;34m(host, port, family, type, proto, flags)\u001B[0m\n\u001B[0;32m    973\u001B[0m addrlist \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 974\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m _socket\u001B[38;5;241m.\u001B[39mgetaddrinfo(host, port, family, \u001B[38;5;28mtype\u001B[39m, proto, flags):\n\u001B[0;32m    975\u001B[0m     af, socktype, proto, canonname, sa \u001B[38;5;241m=\u001B[39m res\n",
      "\u001B[1;31mgaierror\u001B[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mNameResolutionError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[0;32m    786\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[1;32m--> 787\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[0;32m    788\u001B[0m     conn,\n\u001B[0;32m    789\u001B[0m     method,\n\u001B[0;32m    790\u001B[0m     url,\n\u001B[0;32m    791\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout_obj,\n\u001B[0;32m    792\u001B[0m     body\u001B[38;5;241m=\u001B[39mbody,\n\u001B[0;32m    793\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[0;32m    794\u001B[0m     chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    795\u001B[0m     retries\u001B[38;5;241m=\u001B[39mretries,\n\u001B[0;32m    796\u001B[0m     response_conn\u001B[38;5;241m=\u001B[39mresponse_conn,\n\u001B[0;32m    797\u001B[0m     preload_content\u001B[38;5;241m=\u001B[39mpreload_content,\n\u001B[0;32m    798\u001B[0m     decode_content\u001B[38;5;241m=\u001B[39mdecode_content,\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mresponse_kw,\n\u001B[0;32m    800\u001B[0m )\n\u001B[0;32m    802\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    487\u001B[0m         new_e \u001B[38;5;241m=\u001B[39m _wrap_proxy_error(new_e, conn\u001B[38;5;241m.\u001B[39mproxy\u001B[38;5;241m.\u001B[39mscheme)\n\u001B[1;32m--> 488\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m new_e\n\u001B[0;32m    490\u001B[0m \u001B[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001B[39;00m\n\u001B[0;32m    491\u001B[0m \u001B[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    463\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 464\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_conn(conn)\n\u001B[0;32m    465\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError) \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001B[0m, in \u001B[0;36mHTTPSConnectionPool._validate_conn\u001B[1;34m(self, conn)\u001B[0m\n\u001B[0;32m   1092\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m conn\u001B[38;5;241m.\u001B[39mis_closed:\n\u001B[1;32m-> 1093\u001B[0m     conn\u001B[38;5;241m.\u001B[39mconnect()\n\u001B[0;32m   1095\u001B[0m \u001B[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001B[39;00m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\urllib3\\connection.py:704\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    703\u001B[0m sock: socket\u001B[38;5;241m.\u001B[39msocket \u001B[38;5;241m|\u001B[39m ssl\u001B[38;5;241m.\u001B[39mSSLSocket\n\u001B[1;32m--> 704\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m sock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_new_conn()\n\u001B[0;32m    705\u001B[0m server_hostname: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\urllib3\\connection.py:205\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m socket\u001B[38;5;241m.\u001B[39mgaierror \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 205\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NameResolutionError(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost, \u001B[38;5;28mself\u001B[39m, e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SocketTimeout \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mNameResolutionError\u001B[0m: <urllib3.connection.HTTPSConnection object at 0x000001E225DBF7D0>: Failed to resolve 'api.example.com' ([Errno 11001] getaddrinfo failed)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\requests\\adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39murlopen(\n\u001B[0;32m    668\u001B[0m         method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[0;32m    669\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m    670\u001B[0m         body\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mbody,\n\u001B[0;32m    671\u001B[0m         headers\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[0;32m    672\u001B[0m         redirect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    673\u001B[0m         assert_same_host\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    674\u001B[0m         preload_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    675\u001B[0m         decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    676\u001B[0m         retries\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_retries,\n\u001B[0;32m    677\u001B[0m         timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[0;32m    678\u001B[0m         chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    679\u001B[0m     )\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[0;32m    839\u001B[0m     new_e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, new_e)\n\u001B[1;32m--> 841\u001B[0m retries \u001B[38;5;241m=\u001B[39m retries\u001B[38;5;241m.\u001B[39mincrement(\n\u001B[0;32m    842\u001B[0m     method, url, error\u001B[38;5;241m=\u001B[39mnew_e, _pool\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, _stacktrace\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39mexc_info()[\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m    843\u001B[0m )\n\u001B[0;32m    844\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001B[0m, in \u001B[0;36mRetry.increment\u001B[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[0;32m    518\u001B[0m     reason \u001B[38;5;241m=\u001B[39m error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause)\n\u001B[1;32m--> 519\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, reason) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mreason\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    521\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncremented Retry for (url=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, new_retry)\n",
      "\u001B[1;31mMaxRetryError\u001B[0m: HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /stocks/AAPL (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E225DBF7D0>: Failed to resolve 'api.example.com' ([Errno 11001] getaddrinfo failed)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mConnectionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m tool_call \u001B[38;5;129;01min\u001B[39;00m ai_msg\u001B[38;5;241m.\u001B[39mtool_calls:\n\u001B[1;32m----> 2\u001B[0m    tool_msg \u001B[38;5;241m=\u001B[39m get_stock_price\u001B[38;5;241m.\u001B[39minvoke(tool_call)\n\u001B[0;32m      4\u001B[0m    \u001B[38;5;28mprint\u001B[39m(tool_msg\u001B[38;5;241m.\u001B[39mname)\n\u001B[0;32m      5\u001B[0m    \u001B[38;5;28mprint\u001B[39m(tool_call[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124margs\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\langchain_core\\tools\\base.py:508\u001B[0m, in \u001B[0;36mBaseTool.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    501\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[0;32m    502\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    503\u001B[0m     \u001B[38;5;28minput\u001B[39m: Union[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mdict\u001B[39m, ToolCall],\n\u001B[0;32m    504\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    505\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    506\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    507\u001B[0m     tool_input, kwargs \u001B[38;5;241m=\u001B[39m _prep_run_args(\u001B[38;5;28minput\u001B[39m, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 508\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun(tool_input, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\langchain_core\\tools\\base.py:763\u001B[0m, in \u001B[0;36mBaseTool.run\u001B[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001B[0m\n\u001B[0;32m    761\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m error_to_raise:\n\u001B[0;32m    762\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_tool_error(error_to_raise)\n\u001B[1;32m--> 763\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error_to_raise\n\u001B[0;32m    764\u001B[0m output \u001B[38;5;241m=\u001B[39m _format_output(content, artifact, tool_call_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname, status)\n\u001B[0;32m    765\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_tool_end(output, color\u001B[38;5;241m=\u001B[39mcolor, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\langchain_core\\tools\\base.py:732\u001B[0m, in \u001B[0;36mBaseTool.run\u001B[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001B[0m\n\u001B[0;32m    730\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config_param \u001B[38;5;241m:=\u001B[39m _get_runnable_config_param(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run):\n\u001B[0;32m    731\u001B[0m         tool_kwargs \u001B[38;5;241m=\u001B[39m tool_kwargs \u001B[38;5;241m|\u001B[39m {config_param: config}\n\u001B[1;32m--> 732\u001B[0m     response \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run, \u001B[38;5;241m*\u001B[39mtool_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtool_kwargs)\n\u001B[0;32m    733\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponse_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent_and_artifact\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    734\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(response) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\langchain_core\\tools\\structured.py:89\u001B[0m, in \u001B[0;36mStructuredTool._run\u001B[1;34m(self, config, run_manager, *args, **kwargs)\u001B[0m\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config_param \u001B[38;5;241m:=\u001B[39m _get_runnable_config_param(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc):\n\u001B[0;32m     88\u001B[0m         kwargs[config_param] \u001B[38;5;241m=\u001B[39m config\n\u001B[1;32m---> 89\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     90\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStructuredTool does not support sync invocation.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(msg)\n",
      "Cell \u001B[1;32mIn[21], line 12\u001B[0m, in \u001B[0;36mget_stock_price\u001B[1;34m(ticker)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Get the stock price for the stock exchange ticker for the company.\"\"\"\u001B[39;00m\n\u001B[0;32m     11\u001B[0m api_url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://api.example.com/stocks/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mticker\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 12\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(api_url)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[0;32m     14\u001B[0m     data \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mjson()\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\requests\\api.py:73\u001B[0m, in \u001B[0;36mget\u001B[1;34m(url, params, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \n\u001B[0;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m request(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, params\u001B[38;5;241m=\u001B[39mparams, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\requests\\api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m session\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\requests\\adapters.py:700\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    696\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, _SSLError):\n\u001B[0;32m    697\u001B[0m         \u001B[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001B[39;00m\n\u001B[0;32m    698\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m SSLError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m--> 700\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ClosedPoolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    703\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(e, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "\u001B[1;31mConnectionError\u001B[0m: HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /stocks/AAPL (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001E225DBF7D0>: Failed to resolve 'api.example.com' ([Errno 11001] getaddrinfo failed)\"))"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:26:20.250678Z",
     "start_time": "2025-04-22T01:26:20.097564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.messages import HumanMessage\n",
    "import requests\n",
    " \n",
    "@tool\n",
    "def get_stock_price(stock_code: str) -> str:\n",
    "   \"\"\" 한국 증시 종목 코드의 현재 주가 정보를 조회 한다. \"\"\"\n",
    "   api_url = f\"https://m.stock.naver.com/api/stock/{stock_code}/integration\"\n",
    "   response = requests.get(api_url)\n",
    "   if response.status_code == 200:\n",
    "       data = response.json()\n",
    "       return data\n",
    "       # return data.get(\"now\", \"\")\n",
    "   else:\n",
    "       raise ValueError(f\"Failed to fetch stock price for {stock_code}\")\n",
    " \n",
    "# Initialize the LLM with GPT-4o and bind the tools\n",
    "# llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools([get_stock_price])"
   ],
   "id": "725d2cd83b57c3e4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:26:23.567383Z",
     "start_time": "2025-04-22T01:26:22.593051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = [HumanMessage(\"두산밥캣의 현재 주가는 얼마인가요?\")]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)"
   ],
   "id": "1b71a3d9d2298051",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:26:25.996147Z",
     "start_time": "2025-04-22T01:26:25.279614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "   tool_msg = get_stock_price.invoke(tool_call)\n",
    "  \n",
    "   print(tool_msg.name)\n",
    "   print(tool_call['args'])\n",
    "   # print(tool_msg.content)\n",
    "   messages.append(tool_msg)\n",
    "   print()\n",
    " \n",
    "final_response = llm_with_tools.invoke(messages)\n",
    "print(final_response.content)"
   ],
   "id": "de6726670f135341",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_stock_price\n",
      "{'stock_code': '241560'}\n",
      "\n",
      "두산밥캣의 현재 주가는 44,800원입니다.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "``` \n",
    "SKILL은 AI 에이전트가 작업을 수행하고, 결정을 내리며, 환경과 효과적으로 상호작용할 수 있도록 돕습니다. 이러한 작업은 간단한 것부터 고급 추론을 필요로 하는 복잡한 작업까지 다양합니다. 개발자가 수작업으로 설계한 스킬은 정밀성을 제공하지만 유지 관리에 많은 시간이 소요될 수 있습니다. OpenAI나 Google의 Gemini와 같은 플랫폼에서 제공하는 플러그인 스킬은 빠른 통합과 확장성을 가능하게 하지만 맞춤화가 어렵다는 단점이 있습니다. 스킬 계층 구조는 스킬을 체계적인 그룹으로 조직하여 효율성을 높이고 충돌을 줄입니다. 자동화된 스킬 개발은 실시간 코드 생성, 모방 학습, 강화 학습을 포함하여 AI 에이전트가 자신의 능력을 동적으로 적응 및 개선할 수 있게 합니다. 이는 AI 에이전트의 다재다능함과 문제 해결 능력을 향상시켜, 지속적인 개선과 자율적인 스킬 확장을 가능하게 합니다. 에이전트에게 작업 수행에 필요한 역량을 부여하는 가장 중요한 방법 중 하나는 스킬 셋을 구축하고 유지하는 것입니다."
   ],
   "id": "50c300f730d797f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:41:45.704288Z",
     "start_time": "2025-04-22T01:41:45.687985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool \n",
    "import requests\n",
    "\n",
    "@tool\n",
    "def query_wolfram_alpha(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Query Wolfram Alpha to compute mathematical expressions or retrieve information.\n",
    "    Args:\n",
    "        expression (str): The mathematical expression or query to evaluate.\n",
    "    Returns:\n",
    "        str: The result of the computation or the retrieved information.\n",
    "    \"\"\"\n",
    "    api_url = f\"https://api.wolframalpha.com/v1/result?i={requests.utils.quote(expression)}&appid=YOUR_WOLFRAM_ALPHA_APP_ID\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            raise ValueError(f\"Wolfram Alpha API Error: {response.status_code} - {response.text}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise ValueError(f\"Failed to query Wolfram Alpha: {e}\")\n",
    " \n",
    "\n",
    "@tool\n",
    "def trigger_zapier_webhook(zap_id: str, payload: dict) -> str:\n",
    "    \"\"\"\n",
    "    Trigger a Zapier webhook to execute a predefined Zap.\n",
    "    Args:\n",
    "        zap_id (str): The unique identifier for the Zap to be triggered.\n",
    "        payload (dict): The data to send to the Zapier webhook.\n",
    "    Returns:\n",
    "        str: Confirmation message upon successful triggering of the Zap.\n",
    "    Raises:\n",
    "        ValueError: If the API request fails or returns an error.\n",
    "    \"\"\"\n",
    "    zapier_webhook_url = f\"https://hooks.zapier.com/hooks/catch/{zap_id}/\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(zapier_webhook_url, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return f\"Zapier webhook '{zap_id}' successfully triggered.\"\n",
    "        else:\n",
    "            raise ValueError(f\"Zapier API Error: {response.status_code} - {response.text}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise ValueError(f\"Failed to trigger Zapier webhook '{zap_id}': {e}\")\n",
    "\n",
    "@tool\n",
    "def send_slack_message(channel: str, message: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a message to a specified Slack channel.\n",
    "    Args:\n",
    "        channel (str): The Slack channel ID or name where the message will be sent.\n",
    "        message (str): The content of the message to send.\n",
    "    Returns:\n",
    "        str: Confirmation message upon successful sending of the Slack message.\n",
    "    Raises:\n",
    "        ValueError: If the API request fails or returns an error.\n",
    "    \"\"\"\n",
    "    api_url = \"https://slack.com/api/chat.postMessage\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer YOUR_SLACK_BOT_TOKEN\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"channel\": channel,\n",
    "        \"text\": message\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json=payload)\n",
    "        response_data = response.json()\n",
    "        if response.status_code == 200 and response_data.get(\"ok\"):\n",
    "            return f\"Message successfully sent to Slack channel '{channel}'.\"\n",
    "        else:\n",
    "            error_msg = response_data.get(\"error\", \"Unknown error\")\n",
    "            raise ValueError(f\"Slack API Error: {error_msg}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise ValueError(f\"Failed to send message to Slack channel '{channel}': {e}\")\n",
    "\n"
   ],
   "id": "4a8520952c64dd7c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:41:47.719086Z",
     "start_time": "2025-04-22T01:41:47.706856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tools = [query_wolfram_alpha, trigger_zapier_webhook, send_slack_message]\n",
    "\n",
    "# LLM에 도구 바인딩하여 추가 \n",
    "llm_with_tools = llm.bind_tools(tools)"
   ],
   "id": "24831fd66df35e45",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:43:42.164872Z",
     "start_time": "2025-04-22T01:43:41.130271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the LLM with GPT-4o and bind the tools\n",
    "# llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "# llm_with_tools = llm.bind_tools([get_stock_price])\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(\"What is the stock price of Apple?\")]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n"
   ],
   "id": "217901610a2521ca",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    tool_msg = get_stock_price.invoke(tool_call)\n",
    "  \n",
    "    print(tool_msg.name)\n",
    "    print(tool_call['args'])\n",
    "    print(tool_msg.content)\n",
    "    messages.append(tool_msg)\n",
    "    print()\n",
    "\n",
    "final_response = llm_with_tools.invoke(messages)\n",
    "print(final_response.content)"
   ],
   "id": "457d38b1a53168f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "에이전트의 성공은 오케스트레이션 접근 방식에 크게 의존하므로, 에이전트 시스템 구축에 관심이 있는 조직은 사용 사례에 맞는 적절한 계획 전략을 설계하는 데 시간과 에너지를 투자하는 것이 중요합니다.\n",
    "\n",
    "다음은 계획 시스템을 설계할 때 따를 수 있는 몇 가지 모범 사례입니다:\n",
    "\n",
    "시스템의 지연 시간(latency)과 정확성(accuracy) 요구 사항을 신중하게 고려하세요. 이 두 요소 간에는 명확한 상충 관계가 있습니다.\n",
    "시나리오의 사용 사례에 필요한 작업의 일반적인 수를 결정하세요. 이 수가 많을수록 복잡한 계획 접근 방식이 필요할 가능성이 높습니다.\n",
    "이전 작업의 결과에 따라 계획을 얼마나 많이 변경해야 하는지를 평가하세요. 만약 큰 적응이 필요하다면, 점진적인 계획 조정을 허용하는 기술을 고려하세요.\n",
    "다양한 계획 접근 방식을 평가하고 귀하의 사용 사례에 가장 잘 맞는 것을 식별하기 위해 대표적인 테스트 사례 세트를 설계하세요.\n",
    "사용 사례 요구 사항을 충족할 수 있는 가장 간단한 계획 접근 방식을 선택하세요.\n",
    "시나리오에 잘 맞는 오케스트레이션 접근 방식을 선택했다면, 이제 워크플로의 다음 부분인 메모리로 이동하겠습니다. 잘 설계된 시나리오와 단순한 오케스트레이션 접근 방식으로 작게 시작하고, 사용 사례에 따라 필요한 경우 점진적으로 복잡성을 높이는 것이 가치가 있습니다.\n",
    "\n",
    "Shunyu Yao et al.: ReAct: Synergizing Reasoning and Acting in Language Models. ICLR 2023 회의 논문으로 발표됨. https://arxiv.org/pdf/2210.03629"
   ],
   "id": "874412f848988fac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "메모리는 에이전트 시스템의 성공적 운영에 매우 중요한 요소이며, 최근 상호작용의 컨텍스트 윈도우에 의존하는 표준 접근 방식이 많은 사용 사례에는 충분하지만, 더 어려운 시나리오는 더 견고한 접근 방식에 대한 투자로부터 상당한 혜택을 받을 수 있습니다. 이 장에서는 시맨틱 메모리, GraphRAG, 작업 메모리와 같은 여러 접근 방식을 탐구했습니다.\n",
    "이 에이전트 시스템의 메모리에 관한 장에서는 메모리를 어떻게 구조화하고 활용하여 지능형 에이전트의 능력을 향상시킬 수 있는지 다양한 측면에서 심층적으로 탐구했습니다. 컨텍스트 윈도우 관리의 기본 개념부터 시맨틱 메모리와 벡터 스토어의 고급 응용, 동적 지식 그래프와 작업 메모리의 혁신적 실습에 이르기까지, 에이전트 시스템 개발에 중요한 역할을 하는 기술과 기술을 포괄적으로 탐구했습니다.\n",
    "\n",
    "에이전트 응용 프로그램에서 메모리 시스템은 단순히 데이터를 저장하는 것뿐만 아니라, 에이전트가 환경 및 최종 사용자와 상호작용하는 방식을 변형하는 것을 의미합니다. 이러한 시스템을 지속적으로 개선함으로써, 더 지능적이고, 반응성이 뛰어나며, 더 많은 작업을 더 효과적으로 수행할 수 있는 에이전트를 만들 수 있습니다. 다음 장에서는 에이전트가 경험으로부터 학습하여 시간이 지남에 따라 자동으로 개선될 수 있는 방법을 탐구할 것입니다.\n",
    "\n",
    "Whiteboard of Thought: Thinking Step-by-Step Across Modalities, https://arxiv.org/pdf/2406.14562\n",
    "\n",
    "Show Your Work: Scratchpads for Intermediate Computation with Language Models, https://arxiv.org/pdf/2112.00114\n",
    "\n",
    "Learning to Reason with Self-Notes, https://arxiv.org/abs/2305.00833"
   ],
   "id": "c879f0d519b378aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T04:23:28.053850Z",
     "start_time": "2025-04-22T04:23:26.622842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.getenv('AZURE_OPENAI_VERSION')\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv('AZURE_OPENAI_END_POINT')\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv('AZURE_OPENAI_KEY')\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.getenv('DEPLOYMENT_NAME'),  # or your deployment\n",
    "    api_version=os.getenv('AZURE_OPENAI_VERSION'),  # or your api version\n",
    "    temperature=0,\n",
    "    # stream=True,\n",
    "    # max_tokens=40000,\n",
    "    # timeout=None,\n",
    "    # max_retries=2,\n",
    "    # other params...\n",
    ")"
   ],
   "id": "15c9cb7e3eb3793c",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "``` \n",
    "reflextion"
   ],
   "id": "d72a85eb6fbad077"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T04:12:05.503718Z",
     "start_time": "2025-04-22T04:12:05.493433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated, Dict, Any\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langchain_core.messages import HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, TypedDict, Annotated, Optional\n",
    "from operator import add\n",
    "from langchain_core.documents import Document \n",
    "# llm = ChatOpenAI(model=\"gpt-4o\")\n",
    " \n",
    "reflections = []\n",
    " \n",
    "def call_model(state: MessagesState):\n",
    "   response = llm.invoke(state[\"messages\"])\n",
    "   return {\"messages\": response}\n",
    " \n",
    "reflexion_prompt = f\"\"\"You will be given the history of a past experience in which you were\n",
    "placed in an environment and given a task to complete. You were unsuccessful in\n",
    "completing the task. Do not summarize your environment, but rather think about\n",
    "the strategy and path you took to attempt to complete the task.\n",
    "Devise a concise, new plan of action that accounts for your mistake with reference\n",
    "to specific actions that you should have taken. For example, if you tried A and B but forgot C,\n",
    "then devise a plan to achieve C with environment-specific actions. You will need this\n",
    "later when you are solving the same task. Give your plan after \"Plan\".\n",
    " \n",
    "Instruction:\n",
    "i am looking for dairy free and apple variety pack of chips, and price lower than 30.00 dollars\n",
    "[Search]\n",
    " \n",
    "Action: search[dairy free and apple variety pack of chips]\n",
    "Observation:\n",
    "[Back to Search]\n",
    "Page 1 (Total results: 50)\n",
    "[Next >]\n",
    "[B07HRFJWP8]\n",
    "Enjoy Life Foods Soft Baked Ovals, Breakfast Bars, Nut Free Bars, Soy Free, Dairy Free, Non GMO, Gluten Free, Vegan, Variety Pack, 4 Boxes (20 Bars Total)\n",
    "$100.0\n",
    "[B01KMHY5PG]\n",
    "Enjoy Life Soft Baked Chewy Bars, Variety Pack, Nut Free Bars, Soy Free, Dairy Free, Gluten Free, 6 Boxes (30 Total Bars)\n",
    "$21.49\n",
    "[B008D2X8C4]\n",
    "Enjoy Life Lentil Chips Variety Pack, Dairy Free Chips, Soy Free, Nut Free, Non GMO, Vegan, Gluten Free, 24 Bags (0.8 oz)\n",
    "$100.0\n",
    " \n",
    "Action: think[The first two items are not what I want. The third item is the dairy free and apple variety pack of chips I want.]\n",
    "Observation: OK.\n",
    " \n",
    "Action: click[B008D2X8C4]\n",
    "Observation:\n",
    "[Back to Search]\n",
    "[< Prev]\n",
    "flavor name [dill and sour cream][garlic & parmesan][light sea salt][margherita pizza][thai chili lime][variety pack]\n",
    "size [0.8 ounce (pack of 24)][4 ounce (pack of 12)]\n",
    "Price: $100.0\n",
    "Rating: N.A.\n",
    "[Description]\n",
    "[Features]\n",
    "[Reviews]\n",
    "[Buy Now]\n",
    " \n",
    "Action: think[The item has options 'variety pack' and '0.8 ounce (pack of 24)' and seems good to buy.]\n",
    "Observation: OK.\n",
    " \n",
    "Action: click[variety pack]\n",
    "Observation: You have clicked variety pack.\n",
    " \n",
    "Action: click[0.8 ounce (pack of 24)]\n",
    "Observation: You have clicked 0.8 ounce (pack of 24).\n",
    " \n",
    "Action: click[Buy Now]\n",
    " \n",
    "STATUS: FAIL\n",
    " \n",
    "Plan:\n",
    "\"\"\"\n",
    " \n",
    " \n",
    "def update_memory(trial_log_path: str, env_configs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Updates the given env_config with the appropriate reflections.\"\"\"\n",
    "    with open(trial_log_path, 'r') as f:\n",
    "        full_log: str = f.read()\n",
    "        \n",
    "    env_logs: List[str] = full_log.split('#####\\n\\n#####')\n",
    "    assert len(env_logs) == len(env_configs), print(f'bad: {len(env_logs)}, {len(env_configs)}')\n",
    "    for i, env in enumerate(env_configs):\n",
    "        # if unsolved, get reflection and update env config\n",
    "        if not env['is_success'] and not env['skip']:\n",
    "            if len(env['memory']) > 3:\n",
    "                memory: List[str] = env['memory'][-3:]\n",
    "            else:\n",
    "                memory: List[str] = env['memory']\n",
    "            reflection_query: str = _generate_reflection_query(env_logs[i], memory)\n",
    "            reflection: str = get_completion(reflection_query) # type: ignore\n",
    "            env_configs[i]['memory'] += [reflection]\n",
    " \n",
    " \n"
   ],
   "id": "235beb4454a28c72",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T04:12:13.965100Z",
     "start_time": "2025-04-22T04:12:08.227255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"reflexion\", call_model)\n",
    "builder.add_edge(START, \"reflexion\")\n",
    "graph = builder.compile()\n",
    " \n",
    "result = graph.invoke(\n",
    "   {\n",
    "       \"messages\": [\n",
    "           HumanMessage(\n",
    "               reflexion_prompt\n",
    "           )\n",
    "       ]\n",
    "   }\n",
    ")\n",
    "reflections.append(result)\n",
    "print(result)"
   ],
   "id": "be7d8f3fb76178e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='You will be given the history of a past experience in which you were\\nplaced in an environment and given a task to complete. You were unsuccessful in\\ncompleting the task. Do not summarize your environment, but rather think about\\nthe strategy and path you took to attempt to complete the task.\\nDevise a concise, new plan of action that accounts for your mistake with reference\\nto specific actions that you should have taken. For example, if you tried A and B but forgot C,\\nthen devise a plan to achieve C with environment-specific actions. You will need this\\nlater when you are solving the same task. Give your plan after \"Plan\".\\n \\nInstruction:\\ni am looking for dairy free and apple variety pack of chips, and price lower than 30.00 dollars\\n[Search]\\n \\nAction: search[dairy free and apple variety pack of chips]\\nObservation:\\n[Back to Search]\\nPage 1 (Total results: 50)\\n[Next >]\\n[B07HRFJWP8]\\nEnjoy Life Foods Soft Baked Ovals, Breakfast Bars, Nut Free Bars, Soy Free, Dairy Free, Non GMO, Gluten Free, Vegan, Variety Pack, 4 Boxes (20 Bars Total)\\n$100.0\\n[B01KMHY5PG]\\nEnjoy Life Soft Baked Chewy Bars, Variety Pack, Nut Free Bars, Soy Free, Dairy Free, Gluten Free, 6 Boxes (30 Total Bars)\\n$21.49\\n[B008D2X8C4]\\nEnjoy Life Lentil Chips Variety Pack, Dairy Free Chips, Soy Free, Nut Free, Non GMO, Vegan, Gluten Free, 24 Bags (0.8 oz)\\n$100.0\\n \\nAction: think[The first two items are not what I want. The third item is the dairy free and apple variety pack of chips I want.]\\nObservation: OK.\\n \\nAction: click[B008D2X8C4]\\nObservation:\\n[Back to Search]\\n[< Prev]\\nflavor name [dill and sour cream][garlic & parmesan][light sea salt][margherita pizza][thai chili lime][variety pack]\\nsize [0.8 ounce (pack of 24)][4 ounce (pack of 12)]\\nPrice: $100.0\\nRating: N.A.\\n[Description]\\n[Features]\\n[Reviews]\\n[Buy Now]\\n \\nAction: think[The item has options \\'variety pack\\' and \\'0.8 ounce (pack of 24)\\' and seems good to buy.]\\nObservation: OK.\\n \\nAction: click[variety pack]\\nObservation: You have clicked variety pack.\\n \\nAction: click[0.8 ounce (pack of 24)]\\nObservation: You have clicked 0.8 ounce (pack of 24).\\n \\nAction: click[Buy Now]\\n \\nSTATUS: FAIL\\n \\nPlan:\\n', additional_kwargs={}, response_metadata={}, id='04de18ce-ddc4-456b-816c-ec495c46bfb5'), AIMessage(content='Plan:\\n\\n1. **Refine Search Criteria**: Start by refining the search criteria to specifically include \"apple\" in the search query to ensure the results are more relevant. Use a search term like \"dairy free apple chips variety pack under $30\".\\n\\n2. **Filter by Price**: Use available filters to set a price range under $30 to immediately eliminate options that are too expensive.\\n\\n3. **Review Product Details**: Carefully review the product details to ensure the item is indeed a variety pack of apple chips and is dairy-free. Check the flavor options to confirm the presence of apple.\\n\\n4. **Check Product Size and Quantity**: Verify the size and quantity of the product to ensure it meets your needs and is within budget.\\n\\n5. **Read Reviews and Ratings**: Look at customer reviews and ratings to ensure the product quality is satisfactory.\\n\\n6. **Compare Options**: If multiple options are available, compare them based on price, quantity, and customer feedback to make an informed decision.\\n\\n7. **Select and Purchase**: Once a suitable product is found, proceed to purchase, ensuring all selections (like size and variety pack) are correct before finalizing the transaction.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 241, 'prompt_tokens': 585, 'total_tokens': 826, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ee1d74bde0', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-13aade2e-abe6-450e-99ae-c1acf7c3f53b-0', usage_metadata={'input_tokens': 585, 'output_tokens': 241, 'total_tokens': 826})]}\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T04:22:43.746035Z",
     "start_time": "2025-04-22T04:22:43.733863Z"
    }
   },
   "cell_type": "code",
   "source": "result['messages'][-1].content",
   "id": "8283a15752ca4a64",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plan:\\n\\n1. **Refine Search Criteria**: Start by refining the search criteria to specifically include \"apple\" in the search query to ensure the results are more relevant. Use a search term like \"dairy free apple chips variety pack under $30\".\\n\\n2. **Filter by Price**: Use available filters to set a price range under $30 to immediately eliminate options that are too expensive.\\n\\n3. **Review Product Details**: Carefully review the product details to ensure the item is indeed a variety pack of apple chips and is dairy-free. Check the flavor options to confirm the presence of apple.\\n\\n4. **Check Product Size and Quantity**: Verify the size and quantity of the product to ensure it meets your needs and is within budget.\\n\\n5. **Read Reviews and Ratings**: Look at customer reviews and ratings to ensure the product quality is satisfactory.\\n\\n6. **Compare Options**: If multiple options are available, compare them based on price, quantity, and customer feedback to make an informed decision.\\n\\n7. **Select and Purchase**: Once a suitable product is found, proceed to purchase, ensuring all selections (like size and variety pack) are correct before finalizing the transaction.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T04:28:04.152336Z",
     "start_time": "2025-04-22T04:28:04.136682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langchain_core.messages import HumanMessage\n",
    " \n",
    "# Initialize the LLM\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "# Function to call the LLM\n",
    "def call_model(state: MessagesState):\n",
    "   response = llm.invoke(state[\"messages\"])\n",
    "   return {\"messages\": response}\n",
    " \n",
    "class InsightAgent:\n",
    "   def __init__(self):\n",
    "       self.insights = []\n",
    "       self.promoted_insights = []\n",
    "       self.demoted_insights = []\n",
    "       self.reflections = []\n",
    " \n",
    "   def generate_insight(self, observation):\n",
    "       # Use the LLM to generate an insight based on the observation\n",
    "       messages = [HumanMessage(content=f\"Generate an insightful analysis based on the following observation: '{observation}'\")]\n",
    "       # Build the state graph\n",
    "       builder = StateGraph(MessagesState)\n",
    "       builder.add_node(\"generate_insight\", call_model)\n",
    "       builder.add_edge(START, \"generate_insight\")\n",
    "       graph = builder.compile()\n",
    "       # Invoke the graph with the messages\n",
    "       result = graph.invoke({\"messages\": messages})\n",
    "       # Extract the generated insight\n",
    "       generated_insight = result[\"messages\"][-1].content\n",
    "       self.insights.append(generated_insight)\n",
    "       print(f\"Generated: {generated_insight}\")\n",
    "       \n",
    "       return generated_insight"
   ],
   "id": "16dc75d49e9ac1c9",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T04:30:49.855459Z",
     "start_time": "2025-04-22T04:30:43.829610Z"
    }
   },
   "cell_type": "code",
   "source": "insight_agent = InsightAgent().generate_insight('you are awful.')\n",
   "id": "9a3d5be80311f13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: The observation \"you are awful\" is a subjective statement that can be interpreted in various ways depending on the context, tone, and relationship between the speaker and the recipient. Here is an analysis of this observation:\n",
      "\n",
      "1. **Emotional Impact**: Being told \"you are awful\" can have a significant emotional impact on the recipient. It may lead to feelings of hurt, confusion, or defensiveness. Understanding the emotional response is crucial for addressing the situation constructively.\n",
      "\n",
      "2. **Contextual Understanding**: The context in which this statement is made is essential for interpretation. If it is said in a heated argument, it might reflect temporary frustration rather than a deeply held belief. Conversely, if it is part of ongoing criticism, it might indicate deeper issues in the relationship.\n",
      "\n",
      "3. **Source of Criticism**: Consider who is making the statement. Is it coming from a close friend, family member, colleague, or stranger? The relationship dynamics can influence how the statement is perceived and its validity. Feedback from someone who knows you well might be more constructive than from someone who doesn't.\n",
      "\n",
      "4. **Constructive Feedback**: Analyze whether the statement is accompanied by specific examples or constructive feedback. Generalized criticism without context can be less helpful than specific observations that can lead to personal growth or improvement.\n",
      "\n",
      "5. **Self-Reflection**: Use the statement as an opportunity for self-reflection. Are there areas in your behavior or actions that could be improved? Self-awareness is key to personal development, and even harsh criticism can be a catalyst for positive change.\n",
      "\n",
      "6. **Communication Skills**: The way feedback is delivered matters. \"You are awful\" is a blunt statement that lacks tact. Effective communication involves expressing concerns in a way that is respectful and constructive, focusing on specific behaviors rather than personal attacks.\n",
      "\n",
      "7. **Conflict Resolution**: If the statement leads to conflict, consider strategies for resolution. Open dialogue, active listening, and empathy can help address misunderstandings and improve relationships.\n",
      "\n",
      "8. **Resilience and Self-Esteem**: Building resilience and maintaining self-esteem are important when facing negative feedback. Recognize your strengths and achievements to balance criticism and maintain a healthy self-image.\n",
      "\n",
      "In summary, while the statement \"you are awful\" is negative, analyzing its context, source, and impact can provide insights into interpersonal dynamics and opportunities for personal growth. Effective communication and self-reflection are key to transforming criticism into constructive feedback.\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "Learning in Agentic Systems\n",
    "결론\n",
    "에이전트 시스템에서의 학습은 다양한 접근 방식을 포함하며, 각각은 AI 성능과 적응성을 향상시키는 고유한 이점을 제공합니다. 비모수 학습(Non-parametric learning)은 고정된 모델 없이 경험으로부터 학습함으로써 유연성과 실세계 적용 가능성에 중점을 둡니다. 모수 학습(Parametric learning)은 미세 조정을 통해 사전 학습된 모델의 전문성을 향상시켜, 효율성과 성능 간의 균형을 맞춥니다. 전이 학습(Transfer learning)은 기존 지식을 이용하여 새로운 작업에 대한 학습을 신속하고 효과적으로 수행합니다. 이러한 방법론들은 지능적이고 적응력 있으며 효율적인 AI 에이전트를 개발하기 위한 견고한 프레임워크를 형성합니다.\n",
    "\n",
    "1. https://arxiv.org/abs/2005.14165\n",
    "\n",
    "2. Noah Shinn et al.: Reflexion: Language Agents with Verbal Reinforcement Learning. Preprint. Under review. https://arxiv.org/pdf/2303.11366\n",
    "\n",
    "3. Andrew Zhao et al.: ExpeL: LLM Agents Are Experiential Learners. AAAI Conference on Artificial Intelligence 2024. https://arxiv.org/abs/2308.10144"
   ],
   "id": "bd8c549a7e7caa8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e2cff2bbf1b8de45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "33e3d9e45dc61934"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "440b3a79e3034b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "394c893f76e6e888"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
