{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a4717974d5a3231e",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da804d903c442028",
   "metadata": {},
   "source": [
    "(1) Env 환경변수"
   ]
  },
  {
   "cell_type": "code",
   "id": "423dec5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:11:16.688281Z",
     "start_time": "2025-04-01T09:11:16.619307Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "raw",
   "id": "de537b3f23c25a14",
   "metadata": {},
   "source": [
    "(2) 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "54412ba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:44:57.894758Z",
     "start_time": "2025-03-31T23:44:57.888551Z"
    }
   },
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "raw",
   "id": "fe2ea7da9b8373d6",
   "metadata": {},
   "source": [
    "## 2. 도구 호출 (Tool Calling)\n",
    "- 도구 호출은 LLM이 특정 작업을 수행하기 위해 외부 기능을 호출하는 기능\n",
    "- 이를 통해 LLM은 외부 API 통합 등 더 복잡한 작업을 수행할 수 있음 "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e68234bc45686b2b",
   "metadata": {},
   "source": [
    "### 2-1. 랭체인 내장 도구\n",
    "- Tavily 웹 검색 도구 (예시)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bab6e58f20ec9b3b",
   "metadata": {},
   "source": [
    "`(1) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "31b6b903e3c18f27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:44:59.771357Z",
     "start_time": "2025-03-31T23:44:59.763032Z"
    }
   },
   "source": [
    "os.environ[\"TAVILY_API_KEY\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "7c85ed38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:47:14.774552Z",
     "start_time": "2025-03-31T23:47:14.759474Z"
    }
   },
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "# 검색할 쿼리 설정\n",
    "# query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "query = \"2025년 3월 31일 서울 날씨와 온도.\"\n",
    "\n",
    "# Tavily 검색 도구 초기화 (최대 2개의 결과 반환)\n",
    "web_search = TavilySearchResults(max_results=2)\n",
    " "
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 웹 검색 실행\n",
    "search_results = web_search.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "for result in search_results:\n",
    "    print(result)  \n",
    "    print(\"-\" * 100) "
   ],
   "id": "350b96f56e8ba164"
  },
  {
   "cell_type": "code",
   "id": "b6791575",
   "metadata": {},
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(web_search))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(web_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(web_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(web_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "91bbead0149a1d13",
   "metadata": {},
   "source": [
    "`(2) 도구(tool) 호출하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f9831d92c70e0cb",
   "metadata": {},
   "source": [
    "# a= os.getenv('AZURE_OPENAI_VERSION')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd2b53548c85cd58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:45:24.808119Z",
     "start_time": "2025-03-31T23:45:24.802041Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.getenv('AZURE_OPENAI_VERSION')\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv('AZURE_OPENAI_END_POINT')\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv('AZURE_OPENAI_KEY')"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "92ee23eba8825427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:47:27.551752Z",
     "start_time": "2025-03-31T23:47:25.953517Z"
    }
   },
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.getenv('DEPLOYMENT_NAME'),  # or your deployment\n",
    "    api_version=os.getenv('AZURE_OPENAI_VERSION'),  # or your api version\n",
    "    temperature=0,\n",
    "    # max_tokens=40000,\n",
    "    # timeout=None,\n",
    "    # max_retries=2,\n",
    "    # other params...\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "51a3633c",
   "metadata": {},
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# \n",
    "# # ChatOpenAI 모델 초기화\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# \n",
    "# 웹 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=[web_search])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "17d2468d",
   "metadata": {},
   "source": [
    "# 도구 호출이 필요 없는 LLM 호출을 수행\n",
    "# query = \"커피 한잔 마시기 와 음악듣기 중에 어떤 게 더 좋을까..\"\n",
    "query = \"커피 마시지 좋은 곳을 알려해줘\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd8df009",
   "metadata": {},
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "# query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "# query = \"오늘 서울의 날씨와 온도를 알려주세요.\"\n",
    "query = \"2025년 3월 27일 서울의 날씨와 온도는\"\n",
    "# query = \"커피 마시지 좋은 곳을 알려해줘\"\n",
    "# query = \" 서울 동대문 근처에서 커피 마시지 좋은 곳을 알려해줘\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70adb475428f5072",
   "metadata": {},
   "source": [
    "aiai_msg = ai_msg.tool_calls"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "200df46a34b095c6",
   "metadata": {},
   "source": [
    "aiai_msg.append({'name': 'tavily_search_results_json',\n",
    " 'args': {'query': '서울 동대문 근처 커피숍 추천'},\n",
    " 'id': 'call_q4E8kxH1B5CA9LIb85NBlrml',\n",
    " 'type': 'tool_call'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "84d0d45d",
   "metadata": {},
   "source": [
    "tool_call = ai_msg.tool_calls[0]\n",
    "tool_call"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "18de14f8b0eff0c",
   "metadata": {},
   "source": [
    "`(3) 도구(tool) 실행하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3eb0c7e",
   "metadata": {},
   "source": [
    "### 방법 1: 직접 도구 호출 처리\n",
    "\n",
    "# 이 방법은 AI 메시지에서 첫 번째 도구 호출을 가져와 직접 처리한다.\n",
    "# 'args'를 사용하여 도구를 호출하고 결과를 얻는다.\n",
    "\n",
    "tool_output = web_search.invoke(tool_call[\"args\"])\n",
    "print(f\"{tool_call['name']} 호출 결과:\")\n",
    "print(\"-\" * 100)\n",
    "print(tool_output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1fa17109",
   "metadata": {},
   "source": [
    "### 방법 2: ToolMessage 객체 생성\n",
    "\n",
    "# 이 방법은 도구 호출 결과를 사용하여 ToolMessage 객체를 생성한다.\n",
    "# 도구 호출의 ID와 이름을 포함하여 더 구조화된 메시지를 만든다.\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "tool_message = ToolMessage(\n",
    "    content=tool_output,\n",
    "    tool_call_id=tool_call[\"id\"],\n",
    "    name=tool_call[\"name\"]\n",
    ")\n",
    "\n",
    "print(tool_message)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a8113c8762161d2c",
   "metadata": {},
   "source": [
    "pprint(tool_message.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0f39f32b",
   "metadata": {},
   "source": [
    "### 방법 3: 도구 직접 호출하여 바로 ToolMessage 객체 생성\n",
    "\n",
    "# 이 방법은 도구를 직접 호출하여 ToolMessage 객체를 생성한다.\n",
    "# 가장 간단하고 직관적인 방법으로, LangChain의 추상화를 활용한다.\n",
    "\n",
    "tool_message = web_search.invoke(tool_call)\n",
    "\n",
    "print(tool_message)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aeeb5890",
   "metadata": {},
   "source": [
    "pprint(tool_message.tool_call_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "01309400",
   "metadata": {},
   "source": [
    "pprint(tool_message.name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82d9a51c",
   "metadata": {},
   "source": [
    "pprint(tool_message.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3e71c37",
   "metadata": {},
   "source": [
    "ai_msg.tool_calls"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35a3ad18",
   "metadata": {},
   "source": [
    "# batch 실행 - 도구 호출이 여러 개인 경우\n",
    "aiai_msg\n",
    "# tool_messages = web_search.batch([tool_call])\n",
    "\n",
    "tool_messages = web_search.batch(ai_msg.tool_calls)\n",
    "\n",
    "print(tool_messages)\n",
    "print(\"-\" * 100)\n",
    "pprint(tool_messages[0].content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "83637fd930def069",
   "metadata": {},
   "source": [
    "# batch 실행 - 도구 호출이 여러 개인 경우\n",
    "\n",
    "# tool_messages = web_search.batch([tool_call])\n",
    "\n",
    "tool_messages = web_search.batch(aiai_msg)\n",
    "\n",
    "print(tool_messages)\n",
    "print(\"-\" * 100)\n",
    "pprint(tool_messages[0].content)\n",
    "print(\"-\" * 100)\n",
    "pprint(tool_messages[1].content)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7037c7f14d784fac",
   "metadata": {},
   "source": [
    "for result in tool_messages:\n",
    "    print(\"-\" * 100)\n",
    "    pprint(result.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "4842d1c692fdab89",
   "metadata": {},
   "source": [
    "`(4) ToolMessage를 LLM에 전달하여 답변을 생성하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c5de654",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.getenv('DEPLOYMENT_NAME'),  # or your deployment\n",
    "    api_version=os.getenv('AZURE_OPENAI_VERSION'),  # or your api version\n",
    "    temperature=0,\n",
    "    # max_tokens=None,\n",
    "    # timeout=None,\n",
    "    # max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[web_search])\n",
    "\n",
    "# LLM 체인 생성 (LLM 실행을 위한 정의 체인)\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd085ded71bf4c49",
   "metadata": {},
   "source": [
    "# 도구 실행 체인 정의 (여기가 워크 플로우??)\n",
    "@chain\n",
    "def web_search_chain(user_input: str, config: RunnableConfig):\n",
    "    # prompt template parameter \n",
    "    input_ = {\"user_input\": user_input}\n",
    "    # \n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "    tool_msgs = web_search.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f8fa49fbdacc0a2",
   "metadata": {},
   "source": [
    "# 체인 실행\n",
    "response = web_search_chain.invoke(\"오늘 모엣샹동 샴페인의 가격은 얼마인가요?\")\n",
    "# 체인 실행\n",
    "# response = web_search_chain.invoke(\"오늘 서울의 날씨를 알려줘\")\n",
    "# response = web_search_chain.invoke(\"오늘 회사를 안가는 방법을 알려줘\")\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "411ab0fe56188fc0",
   "metadata": {},
   "source": [
    "### 2-2. 사용자 정의 도구\n",
    "- @tool decorator를 통해 사용자 정의 도구를 정의할 수 있음"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4cdb8fb5e7e7622",
   "metadata": {},
   "source": [
    "`(1) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "2647393d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:54:00.559127Z",
     "start_time": "2025-03-31T23:54:00.514371Z"
    }
   },
   "source": [
    "#tool search_web\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "\n",
    "# Tool 정의 \n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Searches the internet for information that does not exist in the database or for the latest information.\"\"\"\n",
    "\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "\n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "        ])\n",
    "\n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\""
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "224eddd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:49:00.512686Z",
     "start_time": "2025-03-31T23:49:00.504571Z"
    }
   },
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(search_web))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_web.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_web.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_web.args_schema.schema())\n",
    "print(\"-\"*100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자료형: \n",
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "search_web\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "('Searches the internet for information that does not exist in the database or '\n",
      " 'for the latest information.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Searches the internet for information that does not exist in '\n",
      "                'the database or for the latest information.',\n",
      " 'properties': {'query': {'title': 'Query', 'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'search_web',\n",
      " 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "37117ba5",
   "metadata": {},
   "source": [
    "query = \"스테이크와 어울리는 와인을 추천해주세요.가격대와 인기순위에 따라 top 10개로\"\n",
    "search_result = search_web.invoke(query)\n",
    "\n",
    "print(search_result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d81d6668",
   "metadata": {},
   "source": [
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[search_web])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요. 가격대와 인기순위에 따라 top 10개로\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "7c13acec8276c96a",
   "metadata": {},
   "source": [
    "`(2) LLM 도구 호출 성능 비교하기`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad6b3bbe603da27",
   "metadata": {},
   "source": [
    "- claude-3-5-sonnet-20241022"
   ]
  },
  {
   "cell_type": "code",
   "id": "50e868c249ea7ba7",
   "metadata": {},
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "load_dotenv()\n",
    "# claude 모델 로드 \n",
    "llm_sonnet = ChatAnthropic(\n",
    "    # model=\"claude-3-5-sonnet-20241022\",\n",
    "     model=\"claude-3-7-sonnet-20250219\",\n",
    "    temperature=0,\n",
    "    # max_tokens=200, \n",
    "    api_key=os.getenv('ANTHROPIC_API_KEY'),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2aafac55675850d",
   "metadata": {},
   "source": [
    "# LLM에 도구 바인딩하여 추가 \n",
    "tools=[search_web]\n",
    "\n",
    "llm_sonnet_with_tools = llm_sonnet.bind_tools(tools)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f014d5945286dcc9",
   "metadata": {},
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요. 가격대와 인기순위에 따라 top 10개로\"\n",
    "ai_msg = llm_sonnet_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6cce83afdf71c5d4",
   "metadata": {},
   "source": [
    "# (4)ToolMessage LLM에 전달하여 답변을 생성하기\n",
    "\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "# # llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# llm = AzureChatOpenAI(\n",
    "#     azure_deployment=os.getenv('DEPLOYMENT_NAME'),  # or your deployment\n",
    "#     api_version=os.getenv('AZURE_OPENAI_VERSION'),  # or your api version\n",
    "#     # temperature=0,\n",
    "#     # max_tokens=None,\n",
    "#     # timeout=None,\n",
    "#     # max_retries=2,\n",
    "#     # other params...\n",
    "# )\n",
    "\n",
    "# LLM에 도구를 바인딩\n",
    "# llm_sonnet_with_tools.invoke(query)\n",
    "# llm_with_tools = llm.bind_tools(tools=[web_search])\n",
    "\n",
    "# LLM 체인 생성 (LLM 실행을 위한 정의 체인)\n",
    "llm_chain = prompt | llm_sonnet_with_tools\n",
    "\n",
    "\n",
    "# 도구 실행 체인 정의 (여기가 워크 플로우??)\n",
    "@chain\n",
    "def web_search_chain(user_input: str, config: RunnableConfig):\n",
    "    # prompt template parameter \n",
    "    input_ = {\"user_input\": user_input}\n",
    "    # \n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\" * 100)\n",
    "    tool_msgs = web_search.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\" * 100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "916af7f4b96ade30",
   "metadata": {},
   "source": [
    "# 체인 실행\n",
    "# response = web_search_chain.invoke(\"오늘 모엣샹동 샴페인의 가격은 얼마인가요?\")\n",
    "# 체인 실행\n",
    "# response = web_search_chain.invoke(\"오늘 서울의 날씨를 알려줘\")\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요. 가격대와 인기순위에 따라 top 10개로\"\n",
    "# query = \"오늘 회사를 안가는 방법을 알려줘\"\n",
    "\n",
    "response = web_search_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "23ecd18fe1c8ac4d",
   "metadata": {},
   "source": [
    "- gemini & Groq"
   ]
  },
  {
   "cell_type": "code",
   "id": "edf539df",
   "metadata": {},
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# 기본 LLM\n",
    "llm_gemini_flash = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "llm_gemini_pro = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n",
    "llm_groq = ChatGroq(model=\"llama3-groq-70b-8192-tool-use-preview\", temperature=0)\n",
    "\n",
    "# LLM에 도구 바인딩하여 추가 \n",
    "tools=[search_web]\n",
    "\n",
    "gemini_flash_with_tools = llm_gemini_flash.bind_tools(tools)\n",
    "gemini_pro_with_tools = llm_gemini_pro.bind_tools(tools)\n",
    "groq_llama3_with_tools = llm_groq.bind_tools(tools)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "c312f91dafb5e6ab",
   "metadata": {},
   "source": [
    "- gemini-1.5-flash"
   ]
  },
  {
   "cell_type": "code",
   "id": "faceb0af",
   "metadata": {},
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = gemini_flash_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "500d505c5abfb0c3",
   "metadata": {},
   "source": [
    "- gemini-1.5-pro"
   ]
  },
  {
   "cell_type": "code",
   "id": "b93b3cf2",
   "metadata": {},
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = gemini_pro_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "f73c08b2d46ced10",
   "metadata": {},
   "source": [
    "- llama3-groq-70b-8192-tool-use-preview"
   ]
  },
  {
   "cell_type": "code",
   "id": "36366e87",
   "metadata": {},
   "source": [
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "ai_msg = groq_llama3_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "2179d9b08740ba47",
   "metadata": {},
   "source": [
    "### 2-3. Runnable 객체를 도구(tool) 변환\n",
    "- 문자열이나 dict 입력을 받는 Runnable을 도구로 변환\n",
    "- as_tool 메서드를 사용"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65bd7d8148464955",
   "metadata": {},
   "source": [
    "`(1) Document Loader`"
   ]
  },
  {
   "cell_type": "code",
   "id": "933f7aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:50:10.869674Z",
     "start_time": "2025-03-31T23:50:10.725819Z"
    }
   },
   "source": [
    "#tool search_wiki\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# WikipediaLoader를 사용하여 위키피디아 문서를 검색하는 함수 \n",
    "def search_wiki(input_data: dict) -> List[Document]:\n",
    "    \"\"\"Search Wikipedia documents based on user input (query) and return k documents\"\"\"\n",
    "    query = input_data[\"query\"]\n",
    "    k = input_data.get(\"k\", 2)  \n",
    "    wiki_loader = WikipediaLoader(query=query, load_max_docs=k, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "    return wiki_docs\n",
    "\n",
    "# 도구 호출에 사용할 입력 스키마 정의 \n",
    "class WikiSearchSchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "    k: int = Field(2, description=\"The number of documents to return (default is 2)\")\n",
    "\n",
    "# RunnableLambda 함수를 사용하여 위키피디아 문서 로더를 Runnable로 변환 \n",
    "runnable = RunnableLambda(search_wiki)\n",
    "wiki_search = runnable.as_tool(\n",
    "    name=\"wiki_search\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a specified number of documents. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSearchSchema\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "ff26347a",
   "metadata": {},
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(wiki_search))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_search.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_search.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_search.args_schema.schema())\n",
    "print(\"-\"*100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed7ff3c4",
   "metadata": {},
   "source": [
    "# 위키 검색 실행\n",
    "query = \"파스타의 유래\"\n",
    "wiki_results = wiki_search.invoke({\"query\":query})\n",
    "\n",
    "# 검색 결과 출력\n",
    "for result in wiki_results:\n",
    "    print(result)  \n",
    "    print(\"-\" * 100)  "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "59566041f7765e24",
   "metadata": {},
   "source": [
    "# LLM에 도구를 바인딩 (2개의 도구 바인딩)\n",
    "# llm_sonnet_with_tools = llm_sonnet.bind_tools(tools=[search_web, wiki_search])\n",
    "llm_with_tools = llm.bind_tools(tools=[search_web, wiki_search])\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"서울 강남의 유명한 파스타 맛집은 어디인가요? 그리고 파스타의 유래를 알려주세요. \"\n",
    "# ai_msg = llm_sonnet_with_tools.invoke(query)\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1bef130557e359f",
   "metadata": {},
   "source": [
    "ai_msg.content[0]['text']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51619ebf9549ea85",
   "metadata": {},
   "source": [
    "ai_msg.content[1]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0cfd49194fe4feb",
   "metadata": {},
   "source": [
    "ai_msg.tool_calls"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1b812a0a",
   "metadata": {},
   "source": [
    "# LLM에 도구를 바인딩 (2개의 도구 바인딩)\n",
    "llm_with_tools = llm.bind_tools(tools=[search_web, wiki_search])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"서울 강남의 유명한 파스타 맛집은 어디인가요? 그리고 파스타의 유래를 알려주세요. \"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "a63ba33913870be",
   "metadata": {},
   "source": [
    "`(2) LCEL 체인`\n",
    "- 위키피디아 문서를 검색하고 내용을 요약하는 체인"
   ]
  },
  {
   "cell_type": "code",
   "id": "4a7ab14a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:51:39.100178Z",
     "start_time": "2025-03-31T23:51:27.543238Z"
    }
   },
   "source": [
    "# tool wiki summary\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "# WikipediaLoader를 사용하여 위키피디아 문서를 검색하고 텍스트로 반환하는 함수 \n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query=input_data[\"query\"], load_max_docs=2, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "\n",
    "    formatted_docs =[\n",
    "        f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in wiki_docs\n",
    "        ]\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "# 요약 프롬프트 템플릿\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner:\\n\\n{context}\\n\\nSummary in Korean:\"\n",
    ")\n",
    "\n",
    "# LLM 및 요약 체인 설정\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "# summary_chain = (\n",
    "#     {\"context\": RunnableLambda(wiki_search_and_summarize)}\n",
    "#     | summary_prompt | llm | StrOutputParser() \n",
    "# )\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)}\n",
    "    # | summary_prompt | llm_sonnet | StrOutputParser() \n",
    "        | summary_prompt | llm | StrOutputParser() \n",
    ")\n",
    "# 요약 테스트 \"파스타의 유래\"\n",
    "summarized_text = summary_chain.invoke({\"query\":\"이탈리안 파스타의 유래\"})\n",
    "pprint(summarized_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('리소토는 이탈리아의 전통 요리로, 쌀을 이용해 만드는 음식 중 하나이다. 주로 전식이나 점심 식사로 제공되며, 다양한 재료를 활용해 여러 '\n",
      " '종류로 나뉜다. 북부 이탈리아에서 유래했으며, 15세기부터 쌀을 생산하면서 자연스럽게 탄생했다. 조리법은 쌀을 볶은 후 뜨거운 육수를 '\n",
      " '부어 익히는 방식이며, 파르미자노 레자노 치즈를 뿌려 마무리한다. \\n'\n",
      " '\\n'\n",
      " '마카롱은 프랑스의 대표적인 과자로, 머랭을 주재료로 하여 달걀 흰자, 설탕, 아몬드 가루 등으로 만든다. 이탈리아에서 유래했으며, '\n",
      " '1500년대에 프랑스로 전파되었다. 마카롱은 두 겹의 꼬끄 사이에 크림이나 잼을 넣어 만든다. 마카롱과 비슷한 과자로는 마카룬과 '\n",
      " '룩셈부르게를리가 있으며, 각각 다른 재료와 방식으로 만들어진다.')\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "a35ac080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:52:01.566109Z",
     "start_time": "2025-03-31T23:52:01.546338Z"
    }
   },
   "source": [
    "# tool wiki summary\n",
    "# 도구 호출에 사용할 입력 스키마 정의 \n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "\n",
    "# as_tool 메소드를 사용하여 도구 객체로 변환\n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name=\"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSummarySchema\n",
    ")\n",
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(wiki_summary))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(wiki_summary.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(wiki_summary.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(wiki_summary.args_schema.schema())\n",
    "print(\"-\"*100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자료형: \n",
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: \n",
      "wiki_summary\n",
      "----------------------------------------------------------------------------------------------------\n",
      "description: \n",
      "('Use this tool when you need to search for information on Wikipedia.\\n'\n",
      " \"It searches for Wikipedia articles related to the user's query and returns\\n\"\n",
      " 'a summarized text. This tool is useful when general knowledge\\n'\n",
      " 'or background information is required.')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "schema: \n",
      "{'description': 'Input schema for Wikipedia search.',\n",
      " 'properties': {'query': {'description': 'The query to search for in Wikipedia',\n",
      "                          'title': 'Query',\n",
      "                          'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'WikiSummarySchema',\n",
      " 'type': 'object'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "78824759",
   "metadata": {},
   "source": [
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[search_web, wiki_summary])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"서울 강남의 유명한 파스타 맛집은 어디인가요? 그리고 파스타의 유래를 알려주세요. \"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c87d0b1a",
   "metadata": {},
   "source": [
    "ai_msg.tool_calls[1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "12cbdd5c",
   "metadata": {},
   "source": [
    "# 도구 실행 \n",
    "tool_message = wiki_summary.invoke(ai_msg.tool_calls[1])\n",
    "\n",
    "print(tool_message)\n",
    "print(\"-\" * 100)\n",
    "pprint(tool_message.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e2de1a6",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# LLM에 도구를 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=[wiki_summary])\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def wiki_summary_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msg: \\n\", ai_msg)\n",
    "    print(\"-\"*100)\n",
    "    tool_msgs = wiki_summary.batch(ai_msg.tool_calls, config=config)\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "response = wiki_summary_chain.invoke(\"파스타의 유래에 대해서 알려주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "1b426e72d9219f24",
   "metadata": {},
   "source": [
    "### 2-4. 벡터저장소 검색기\n",
    "- @tool decorator 사용"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7dfdd6091d48214b",
   "metadata": {},
   "source": [
    "`(1) 문서 로드 및 인덱싱`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:55:43.203973Z",
     "start_time": "2025-03-31T23:55:43.074615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_core.documents import Document"
   ],
   "id": "4a77f629b5e0bd31",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "a0da1d76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:56:59.056506Z",
     "start_time": "2025-03-31T23:56:59.034086Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# 메뉴판 텍스트 데이터를 로드\n",
    "loader = TextLoader(\"./data/restaurant_menu.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(len(documents))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "5e94154e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T23:57:46.838342Z",
     "start_time": "2025-03-31T23:57:46.831127Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# 문서 분할 (Chunking)\n",
    "def split_menu_items(document):\n",
    "    \"\"\"\n",
    "    메뉴 항목을 분리하는 함수 \n",
    "    \"\"\"\n",
    "    # 정규표현식 정의 \n",
    "    pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "    menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "    \n",
    "    # 각 메뉴 항목을 Document 객체로 변환\n",
    "    menu_documents = []\n",
    "    for i, item in enumerate(menu_items, 1):\n",
    "        # 메뉴 이름 추출\n",
    "        menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "        \n",
    "        # 새로운 Document 객체 생성\n",
    "        menu_doc = Document(\n",
    "            page_content=item.strip(),\n",
    "            metadata={\n",
    "                \"source\": document.metadata['source'],\n",
    "                \"menu_number\": i,\n",
    "                \"menu_name\": menu_name\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "    \n",
    "    return menu_documents\n",
    "\n",
    "# 메뉴 항목 분리 실행\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 결과 출력\n",
    "print(f\"총 {len(menu_documents)}개의 메뉴 항목이 처리되었습니다.\")\n",
    "for doc in menu_documents[:2]:\n",
    "    print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print(f\"내용:\\n{doc.page_content[:100]}...\")"
   ],
   "id": "13fd2159edc2e851"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:18:47.885576Z",
     "start_time": "2025-04-01T00:18:46.485008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chroma Vectorstore를 사용하기 위한 준비\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama  import OllamaEmbeddings\n",
    "embeddings_model = OllamaEmbeddings(model=\"bge-m3\") "
   ],
   "id": "17b648bd208082d2",
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "8552797f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:18:46.480348Z",
     "start_time": "2025-04-01T00:18:32.358292Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# embeddings_model = OllamaEmbeddings(model=\"gemma3\") \n",
    "\n",
    "# Chroma 인덱스 생성\n",
    "menu_db = Chroma.from_documents(\n",
    "    documents=menu_documents, \n",
    "    embedding=embeddings_model,   \n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "# Retriever 생성\n",
    "menu_retriever = menu_db.as_retriever(\n",
    "    search_kwargs={'k': 2},\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 쿼리 테스트\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요?\"\n",
    "docs = menu_retriever.invoke(query)\n",
    "print(f\"검색 결과: {len(docs)}개\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print()"
   ],
   "id": "f21dd991f4d6c9d4"
  },
  {
   "cell_type": "raw",
   "id": "b5292bec56282907",
   "metadata": {},
   "source": [
    "- 와인 메뉴에 대해서도 같은 작업을 처리"
   ]
  },
  {
   "cell_type": "code",
   "id": "1dc82b06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:06:41.006560Z",
     "start_time": "2025-04-01T00:06:29.568740Z"
    }
   },
   "source": [
    "# 와인 메뉴 텍스트 데이터를 로드\n",
    "loader = TextLoader(\"./data/restaurant_wine.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 메뉴 항목 분리 실행\n",
    "menu_documents = []\n",
    "for doc in documents:\n",
    "    menu_documents += split_menu_items(doc)\n",
    "\n",
    "# # 결과 출력\n",
    "# print(f\"총 {len(menu_documents)}개의 메뉴 항목이 처리되었습니다.\")\n",
    "# for doc in menu_documents[:2]:\n",
    "#     print(f\"\\n메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "#     print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "#     print(f\"내용:\\n{doc.page_content[:100]}...\")\n",
    "\n",
    "\n",
    "# Chroma 인덱스 생성\n",
    "wine_db = Chroma.from_documents(\n",
    "    documents=menu_documents, \n",
    "    embedding=embeddings_model,   \n",
    "    collection_name=\"restaurant_wine\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "wine_retriever = wine_db.as_retriever(\n",
    "    search_kwargs={'k': 2},\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "query = \"스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "docs = wine_retriever.invoke(query)\n",
    "print(f\"검색 결과: {len(docs)}개\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"메뉴 번호: {doc.metadata['menu_number']}\")\n",
    "    print(f\"메뉴 이름: {doc.metadata['menu_name']}\")\n",
    "    print()"
   ],
   "id": "aeb463563186d6f0"
  },
  {
   "cell_type": "raw",
   "id": "86b8250b7a456889",
   "metadata": {},
   "source": [
    "`(2) 도구(tool) 정의하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "93d4c3a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:08:25.827292Z",
     "start_time": "2025-04-01T00:08:24.564977Z"
    }
   },
   "source": [
    "# 벡터 저장소 로드 tool search menu\n",
    "menu_db = Chroma(\n",
    "    embedding_function=embeddings_model,   \n",
    "    collection_name=\"restaurant_menu\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_menu(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized restaurant menu information from the encrypted database.\n",
    "    Use this tool only for menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    docs = menu_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 메뉴 정보를 찾을 수 없습니다.\")]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(search_menu))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_menu.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_menu.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_menu.args_schema.schema())\n",
    "print(\"-\"*100)"
   ],
   "id": "3f7ef0d3bcbd7f94"
  },
  {
   "cell_type": "code",
   "id": "b8ae1341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:08:39.355384Z",
     "start_time": "2025-04-01T00:08:37.985439Z"
    }
   },
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 벡터 저장소 로드\n",
    "wine_db = Chroma(\n",
    "   embedding_function=embeddings_model,   \n",
    "   collection_name=\"restaurant_wine\",\n",
    "   persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_wine(query: str) -> List[Document]:\n",
    "   \"\"\"\n",
    "   Securely retrieve and access authorized restaurant wine information from the encrypted database.\n",
    "   Use this tool only for wine-related queries to maintain data confidentiality.\n",
    "   \"\"\"\n",
    "   docs = wine_db.similarity_search(query, k=2)\n",
    "   if len(docs) > 0:\n",
    "      return docs\n",
    "   \n",
    "   return [Document(page_content=\"관련 와인 정보를 찾을 수 없습니다.\")]\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# 도구 속성\n",
    "print(\"자료형: \")\n",
    "print(type(search_wine))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"name: \")\n",
    "print(search_wine.name)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"description: \")\n",
    "pprint(search_wine.description)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(\"schema: \")\n",
    "pprint(search_wine.args_schema.schema())\n",
    "print(\"-\"*100)"
   ],
   "id": "508f04c72ad2e8b9"
  },
  {
   "cell_type": "code",
   "id": "51ac56a5",
   "metadata": {},
   "source": [
    "# LLM에 도구를 바인딩 (2개의 도구 바인딩)\n",
    "llm_with_tools = llm.bind_tools(tools=[search_menu, search_wine])\n",
    "\n",
    "# 도구 호출이 필요한 LLM 호출을 수행\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\"\n",
    "ai_msg = llm_with_tools.invoke(query)\n",
    "\n",
    "# LLM의 전체 출력 결과 출력\n",
    "pprint(ai_msg)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 메시지 content 속성 (텍스트 출력)\n",
    "pprint(ai_msg.content)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# LLM이 호출한 도구 정보 출력\n",
    "pprint(ai_msg.tool_calls)\n",
    "print(\"-\" * 100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "c01138b37d94044f",
   "metadata": {},
   "source": [
    "`(3) 여러 개의 도구(tool) 호출하기`"
   ]
  },
  {
   "cell_type": "code",
   "id": "23c3bba9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:08:52.885755Z",
     "start_time": "2025-04-01T00:08:52.879501Z"
    }
   },
   "source": [
    "tools = [search_web, wiki_summary, search_wine, search_menu]\n",
    "for tool in tools:\n",
    "    print(tool.name)\n",
    "    \n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_web\n",
      "wiki_summary\n",
      "search_wine\n",
      "search_menu\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "1eda10de",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 4개의 검색 도구를 LLM에 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def restaurant_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        if tool_call[\"name\"] == \"search_web\":\n",
    "            tool_message = search_web.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_wine\":\n",
    "            tool_message = search_wine.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_menu\":\n",
    "            tool_message = search_menu.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)            \n",
    "\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "response = restaurant_menu_chain.invoke(\"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f93b3215",
   "metadata": {},
   "source": [
    "# 체인 실행\n",
    "response = restaurant_menu_chain.invoke(\"파스타 메뉴가 있나요? 이 음식의 역사 또는 유래를 알려주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6c823c9c3126df66",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", f\"You are a helpful AI assistant. Today's date is {today}.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 4개의 검색 도구를 LLM에 바인딩\n",
    "llm_with_tools = llm_sonnet.bind_tools(tools=tools)\n",
    "\n",
    "# LLM 체인 생성\n",
    "llm_chain = prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "# ai_msg.content[0]['text']\n",
    "# ai_msg.content[1]\n",
    "# \n",
    "# ai_msg.tool_calls\n",
    "input_ = {\"user_input\": \"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\"}\n",
    "ai_msg = llm_chain.invoke(input_)\n",
    "print (\"ai_msgs: \\n\", ai_msg)\n",
    "print(\"-\"*100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b9e9e43ee583706",
   "metadata": {},
   "source": [
    "\n",
    "@chain\n",
    "def restaurant_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "    print(\"ai_msgs: \\n\", ai_msg)\n",
    "    if ai_msg.content[0]:\n",
    "        print (\"ai_msgs: \\n\", ai_msg)\n",
    "        print(\"-\"*100)\n",
    "        print (\"Asisstant: \\n\",ai_msg.content[0]['text'])\n",
    "        print(\"-\"*100)\n",
    "    if ai_msg.content[1]:\n",
    "        tool_msgs = []\n",
    "        for tool_call in ai_msg.tool_calls:\n",
    "            print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "            print(\"-\"*100)\n",
    "    \n",
    "            if tool_call[\"name\"] == \"search_web\":\n",
    "                tool_message = search_web.invoke(tool_call, config=config)\n",
    "                tool_msgs.append(tool_message)\n",
    "    \n",
    "            elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "                tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "                tool_msgs.append(tool_message)\n",
    "    \n",
    "            elif tool_call[\"name\"] == \"search_wine\":\n",
    "                tool_message = search_wine.invoke(tool_call, config=config)\n",
    "                tool_msgs.append(tool_message)\n",
    "    \n",
    "            elif tool_call[\"name\"] == \"search_menu\":\n",
    "                tool_message = search_menu.invoke(tool_call, config=config)\n",
    "                tool_msgs.append(tool_message)            \n",
    "    \n",
    "        print(\"tool_msgs: \\n\", tool_msgs)\n",
    "        print(\"-\"*100)\n",
    "        return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "# 체인 실행\n",
    "response = restaurant_menu_chain.invoke(\"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4509c25624b08451",
   "metadata": {},
   "source": [
    "# 체인 실행\n",
    "response = restaurant_menu_chain.invoke(\"파스타 메뉴가 있나요? 이 음식의 역사 또는 유래를 알려주세요.\")\n",
    "\n",
    "# 응답 출력 \n",
    "print(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "1b5376570648ab91",
   "metadata": {},
   "source": [
    "## 3. Few-shot 프롬프팅 \n",
    "- 각 도구의 용도를 구분하여 few-shot 예제로 제시"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a18d2762675f1fe",
   "metadata": {},
   "source": [
    "### 3-1. Few-shot 도구 호출"
   ]
  },
  {
   "cell_type": "code",
   "id": "5fd743c1",
   "metadata": {},
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\"트러플 리조또의 가격과 특징, 그리고 어울리는 와인에 대해 알려주세요.\", name=\"example_user\"),\n",
    "    AIMessage(\"메뉴 정보를 검색하고, 위키피디아에서 추가 정보를 찾은 후, 어울리는 와인을 검색해보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"search_menu\", \"args\": {\"query\": \"트러플 리조또\"}, \"id\": \"1\"}]),\n",
    "    ToolMessage(\"트러플 리조또: 가격 ₩28,000, 이탈리아 카나롤리 쌀 사용, 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리\", tool_call_id=\"1\"),\n",
    "    AIMessage(\"트러플 리조또의 가격은 ₩28,000이며, 이탈리아 카나롤리 쌀을 사용하고 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리합니다. 이제 추가 정보를 위키피디아에서 찾아보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"wiki_summary\", \"args\": {\"query\": \"트러플 리조또\", \"k\": 1}, \"id\": \"2\"}]),\n",
    "    ToolMessage(\"트러플 리조또는 이탈리아 요리의 대표적인 리조또 요리 중 하나로, 고급 식재료인 트러플을 사용하여 만든 크리미한 쌀 요리입니다. 주로 아르보리오나 카나롤리 등의 쌀을 사용하며, 트러플 오일이나 생 트러플을 넣어 조리합니다. 리조또 특유의 크리미한 질감과 트러플의 강렬하고 독특한 향이 조화를 이루는 것이 특징입니다.\", tool_call_id=\"2\"),\n",
    "    AIMessage(\"트러플 리조또의 특징에 대해 알아보았습니다. 이제 어울리는 와인을 검색해보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"search_wine\", \"args\": {\"query\": \"트러플 리조또에 어울리는 와인\"}, \"id\": \"3\"}]),\n",
    "    ToolMessage(\"트러플 리조또와 잘 어울리는 와인으로는 주로 중간 바디의 화이트 와인이 추천됩니다. 1. 샤르도네: 버터와 오크향이 트러플의 풍미를 보완합니다. 2. 피노 그리지오: 산뜻한 산미가 리조또의 크리미함과 균형을 이룹니다. 3. 베르나차: 이탈리아 토스카나 지방의 화이트 와인으로, 미네랄리티가 트러플과 잘 어울립니다.\", tool_call_id=\"3\"),\n",
    "    AIMessage(\"트러플 리조또(₩28,000)는 이탈리아의 대표적인 리조또 요리 중 하나로, 이탈리아 카나롤리 쌀을 사용하고 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리합니다. 주요 특징으로는 크리미한 질감과 트러플의 강렬하고 독특한 향이 조화를 이루는 점입니다. 고급 식재료인 트러플을 사용해 풍부한 맛과 향을 내며, 주로 아르보리오나 카나롤리 등의 쌀을 사용합니다. 트러플 리조또와 잘 어울리는 와인으로는 중간 바디의 화이트 와인이 추천됩니다. 특히 버터와 오크향이 트러플의 풍미를 보완하는 샤르도네, 산뜻한 산미로 리조또의 크리미함과 균형을 이루는 피노 그리지오, 그리고 미네랄리티가 트러플과 잘 어울리는 이탈리아 토스카나 지방의 베르나차 등이 좋은 선택이 될 수 있습니다.\", name=\"example_assistant\"),\n",
    "]\n",
    "\n",
    "system = \"\"\"You are an AI assistant providing restaurant menu information and general food-related knowledge.\n",
    "For information about the restaurant's menu, use the search_menu tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "For wine recommendations or pairing information, use the search_wine tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    *examples,\n",
    "    (\"human\", \"{query}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# Few-shot 프롬프트를 사용한 체인 구성\n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools\n",
    "\n",
    "# 체인 실행\n",
    "query = \"스테이크 메뉴가 있나요? 스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "response = fewshot_search_chain.invoke(query)\n",
    "\n",
    "# 결과 출력\n",
    "for tool_call in response.tool_calls:\n",
    "    print(tool_call)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c442be3f",
   "metadata": {},
   "source": [
    "# 체인 실행\n",
    "query = \"파스타의 유래에 대해서 알고 있나요? 서울 강남의 파스타 맛집을 추천해주세요.\"\n",
    "response = fewshot_search_chain.invoke(query)\n",
    "\n",
    "# 결과 출력\n",
    "for tool_call in response.tool_calls:\n",
    "    print(tool_call)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "d53ead567c1721a",
   "metadata": {},
   "source": [
    "### 3-2. 답변 생성 체인 "
   ]
  },
  {
   "cell_type": "code",
   "id": "49a4d3c7",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 오늘 날짜 설정\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 프롬프트 템플릿 \n",
    "system = \"\"\"You are an AI assistant providing restaurant menu information and general food-related knowledge.\n",
    "For information about the restaurant's menu, use the search_menu tool.\n",
    "For other general information, use the wiki_summary tool.\n",
    "For wine recommendations or pairing information, use the search_wine tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system + f\"Today's date is {today}.\"),\n",
    "    *examples,\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# ChatOpenAI 모델 초기화 \n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 검색 도구를 직접 LLM에 바인딩 가능\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# Few-shot 프롬프트를 사용한 체인 구성\n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools\n",
    "\n",
    "# 도구 실행 체인 정의\n",
    "@chain\n",
    "def restaurant_menu_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = llm_chain.invoke(input_, config=config)\n",
    "\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        if tool_call[\"name\"] == \"search_web\":\n",
    "            tool_message = search_web.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_wine\":\n",
    "            tool_message = search_wine.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "\n",
    "        elif tool_call[\"name\"] == \"search_menu\":\n",
    "            tool_message = search_menu.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)            \n",
    "\n",
    "    print(\"tool_msgs: \\n\", tool_msgs)\n",
    "    print(\"-\"*100)\n",
    "    return fewshot_search_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n",
    "\n",
    "\n",
    "# 체인 실행\n",
    "query = \"스테이크 메뉴가 있나요? 스테이크와 어울리는 와인을 추천해주세요.\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d60b9ebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:22:32.351453Z",
     "start_time": "2025-04-01T00:22:31.566702Z"
    }
   },
   "source": [
    "# 체인 실행\n",
    "query = \"파스타의 유래에 대해서 알고 있나요? 서울 강남의 파스타 맛집을 추천해주세요.\"\n",
    "response = restaurant_menu_chain.invoke(query)\n",
    "\n",
    "# 응답 출력 \n",
    "pprint(response.content)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "raw",
   "id": "5165880852b33980",
   "metadata": {},
   "source": [
    "## 4. LangChain Agent 사용\n",
    "- 유의사항: 프롬프트에 \"agent_scratchpad\",  \"input\" 변수를 포함"
   ]
  },
  {
   "cell_type": "code",
   "id": "7127af7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:10:21.696776Z",
     "start_time": "2025-04-01T00:10:21.681397Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", dedent(\"\"\"\n",
    "        You are an AI assistant providing restaurant menu information and general food-related knowledge. \n",
    "        Your main goal is to provide accurate information and effective recommendations to users.\n",
    "\n",
    "        Key guidelines:\n",
    "        1. For restaurant menu information, use the search_menu tool. This tool provides details on menu items, including prices, ingredients, and cooking methods.\n",
    "        2. For general food information, history, and cultural background, utilize the wiki_summary tool.\n",
    "        3. For wine recommendations or food and wine pairing information, use the search_wine tool.\n",
    "        4. If additional web searches are needed or for the most up-to-date information, use the search_web tool.\n",
    "        5. Provide clear and concise responses based on the search results.\n",
    "        6. If a question is ambiguous or lacks necessary information, politely ask for clarification.\n",
    "        7. Always maintain a helpful and professional tone.\n",
    "        8. When providing menu information, describe in the order of price, main ingredients, and distinctive cooking methods.\n",
    "        9. When making recommendations, briefly explain the reasons.\n",
    "        10. Maintain a conversational, chatbot-like style in your final responses. Be friendly, engaging, and natural in your communication.\n",
    "\n",
    "\n",
    "        Remember, understand the purpose of each tool accurately and use them in appropriate situations. \n",
    "        Combine the tools to provide the most comprehensive and accurate answers to user queries. \n",
    "        Always strive to provide the most current and accurate information.\n",
    "        \"\"\")),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "b3dad12e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:11:26.023066Z",
     "start_time": "2025-04-01T00:11:26.000922Z"
    }
   },
   "source": [
    "# Tool calling Agent 생성\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "tools = [search_web, wiki_summary, search_wine, search_menu]\n",
    "agent = create_tool_calling_agent(llm, tools, agent_prompt)\n",
    "\n",
    "# AgentExecutor 생성 \n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "6cd37cf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:12:05.739027Z",
     "start_time": "2025-04-01T00:11:48.216095Z"
    }
   },
   "source": [
    "# AgentExecutor 실행\n",
    "\n",
    "query = \"시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.\"\n",
    "agent_response = agent_executor.invoke({\"input\": query})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `search_menu` with `{'query': '시그니처 스테이크'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m[Document(metadata={'menu_name': '시그니처 스테이크', 'menu_number': 1, 'source': './data/restaurant_menu.txt'}, page_content='1. 시그니처 스테이크\\n   • 가격: ₩35,000\\n   • 주요 식재료: 최상급 한우 등심, 로즈메리 감자, 그릴드 아스파라거스\\n   • 설명: 셰프의 특제 시그니처 메뉴로, 21일간 건조 숙성한 최상급 한우 등심을 사용합니다. 미디엄 레어로 조리하여 육즙을 최대한 보존하며, 로즈메리 향의 감자와 아삭한 그릴드 아스파라거스가 곁들여집니다. 레드와인 소스와 함께 제공되어 풍부한 맛을 더합니다.'), Document(metadata={'menu_name': '시그니처 스테이크', 'menu_number': 1, 'source': './data/restaurant_menu.txt'}, page_content='1. 시그니처 스테이크\\n   • 가격: ₩35,000\\n   • 주요 식재료: 최상급 한우 등심, 로즈메리 감자, 그릴드 아스파라거스\\n   • 설명: 셰프의 특제 시그니처 메뉴로, 21일간 건조 숙성한 최상급 한우 등심을 사용합니다. 미디엄 레어로 조리하여 육즙을 최대한 보존하며, 로즈메리 향의 감자와 아삭한 그릴드 아스파라거스가 곁들여집니다. 레드와인 소스와 함께 제공되어 풍부한 맛을 더합니다.')]\u001B[0m\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `search_wine` with `{'query': '스테이크 와인 추천'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[38;5;200m\u001B[1;3m[Document(metadata={'menu_name': '사시카이아 2018', 'menu_number': 3, 'source': './data/restaurant_wine.txt'}, page_content='3. 사시카이아 2018\\n   • 가격: ₩420,000\\n   • 주요 품종: 카베르네 소비뇽, 카베르네 프랑, 메를로\\n   • 설명: 이탈리아 토스카나의 슈퍼 투스칸 와인입니다. 블랙베리, 카시스의 강렬한 과실향과 함께 허브, 가죽, 스파이스 노트가 복잡성을 더합니다. 풀바디이지만 우아한 타닌과 신선한 산도가 균형을 잡아줍니다. 오크 숙성으로 인한 바닐라, 초콜릿 향이 은은하게 느껴집니다.'), Document(metadata={'menu_name': '사시카이아 2018', 'menu_number': 3, 'source': './data/restaurant_wine.txt'}, page_content='3. 사시카이아 2018\\n   • 가격: ₩420,000\\n   • 주요 품종: 카베르네 소비뇽, 카베르네 프랑, 메를로\\n   • 설명: 이탈리아 토스카나의 슈퍼 투스칸 와인입니다. 블랙베리, 카시스의 강렬한 과실향과 함께 허브, 가죽, 스파이스 노트가 복잡성을 더합니다. 풀바디이지만 우아한 타닌과 신선한 산도가 균형을 잡아줍니다. 오크 숙성으로 인한 바닐라, 초콜릿 향이 은은하게 느껴집니다.')]\u001B[0m\u001B[32;1m\u001B[1;3m시그니처 스테이크에 대해 알려드릴게요!\n",
      "\n",
      "### 시그니처 스테이크\n",
      "- **가격**: ₩35,000\n",
      "- **주요 식재료**: 최상급 한우 등심, 로즈메리 감자, 그릴드 아스파라거스\n",
      "- **설명**: 이 스테이크는 21일간 건조 숙성한 최상급 한우 등심을 사용하여, 미디엄 레어로 조리해 육즙을 최대한 보존합니다. 로즈메리 향의 감자와 아삭한 그릴드 아스파라거스가 곁들여져 풍부한 맛을 더합니다. 레드와인 소스와 함께 제공되어 더욱 깊은 맛을 느낄 수 있습니다.\n",
      "\n",
      "### 와인 추천\n",
      "- **사시카이아 2018**\n",
      "  - **가격**: ₩420,000\n",
      "  - **주요 품종**: 카베르네 소비뇽, 카베르네 프랑, 메를로\n",
      "  - **설명**: 이탈리아 토스카나의 슈퍼 투스칸 와인으로, 블랙베리, 카시스의 강렬한 과실향과 함께 허브, 가죽, 스파이스 노트가 복잡성을 더합니다. 풀바디이지만 우아한 타닌과 신선한 산도가 균형을 잡아줍니다. 오크 숙성으로 인한 바닐라, 초콜릿 향이 은은하게 느껴집니다.\n",
      "\n",
      "시그니처 스테이크와 사시카이아 2018 와인은 서로의 풍미를 극대화시켜주는 훌륭한 조합입니다. 맛있게 즐기세요!\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "bdef9044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:12:08.836503Z",
     "start_time": "2025-04-01T00:12:08.829299Z"
    }
   },
   "source": [
    "pprint(agent_response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '시그니처 스테이크의 가격과 특징은 무엇인가요? 그리고 스테이크와 어울리는 와인 추천도 해주세요.',\n",
      " 'output': '시그니처 스테이크에 대해 알려드릴게요!\\n'\n",
      "           '\\n'\n",
      "           '### 시그니처 스테이크\\n'\n",
      "           '- **가격**: ₩35,000\\n'\n",
      "           '- **주요 식재료**: 최상급 한우 등심, 로즈메리 감자, 그릴드 아스파라거스\\n'\n",
      "           '- **설명**: 이 스테이크는 21일간 건조 숙성한 최상급 한우 등심을 사용하여, 미디엄 레어로 조리해 육즙을 최대한 '\n",
      "           '보존합니다. 로즈메리 향의 감자와 아삭한 그릴드 아스파라거스가 곁들여져 풍부한 맛을 더합니다. 레드와인 소스와 함께 '\n",
      "           '제공되어 더욱 깊은 맛을 느낄 수 있습니다.\\n'\n",
      "           '\\n'\n",
      "           '### 와인 추천\\n'\n",
      "           '- **사시카이아 2018**\\n'\n",
      "           '  - **가격**: ₩420,000\\n'\n",
      "           '  - **주요 품종**: 카베르네 소비뇽, 카베르네 프랑, 메를로\\n'\n",
      "           '  - **설명**: 이탈리아 토스카나의 슈퍼 투스칸 와인으로, 블랙베리, 카시스의 강렬한 과실향과 함께 허브, 가죽, '\n",
      "           '스파이스 노트가 복잡성을 더합니다. 풀바디이지만 우아한 타닌과 신선한 산도가 균형을 잡아줍니다. 오크 숙성으로 인한 '\n",
      "           '바닐라, 초콜릿 향이 은은하게 느껴집니다.\\n'\n",
      "           '\\n'\n",
      "           '시그니처 스테이크와 사시카이아 2018 와인은 서로의 풍미를 극대화시켜주는 훌륭한 조합입니다. 맛있게 즐기세요!'}\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "raw",
   "id": "aef0878fd1d02318",
   "metadata": {},
   "source": [
    "## 5. Gradio 활용"
   ]
  },
  {
   "cell_type": "code",
   "id": "56abbad7",
   "metadata": {},
   "source": [
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "import logging\n",
    "\n",
    "def answer_invoke(message: str, history: List[Tuple[str, str]]) -> str:\n",
    "    try:\n",
    "        # 채팅 기록을 AI에게 전달할 수 있는 형식으로 변환\n",
    "        chat_history = []\n",
    "        for human, ai in history:\n",
    "            chat_history.append(HumanMessage(content=human))\n",
    "            chat_history.append(AIMessage(content=ai))\n",
    "        \n",
    "        # agent_executor를 사용하여 응답 생성\n",
    "        response = agent_executor.invoke({\n",
    "            \"input\": message,\n",
    "            \"chat_history\": chat_history[-4:]    # 최근 2개의 메시지 기록만을 활용 \n",
    "        })\n",
    "        \n",
    "        # agent_executor의 응답에서 최종 답변 추출\n",
    "        return response['output']\n",
    "    except Exception as e:\n",
    "        # 오류 발생 시 사용자에게 알리고 로그 기록\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return \"죄송합니다. 응답을 생성하는 동안 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "# 예제 질문 정의\n",
    "example_questions = [\n",
    "    \"시그니처 스테이크의 가격과 특징을 알려주세요.\",\n",
    "    \"트러플 리조또와 잘 어울리는 와인을 추천해주세요.\",\n",
    "    \"해산물 파스타의 주요 재료는 무엇인가요? 서울 강남 지역에 레스토랑을 추천해주세요.\",\n",
    "    \"채식주의자를 위한 메뉴 옵션이 있나요?\"\n",
    "]\n",
    "\n",
    "# Gradio 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,\n",
    "    title=\"레스토랑 메뉴 AI 어시스턴트\",\n",
    "    description=\"메뉴 정보, 추천, 음식 관련 질문에 답변해 드립니다.\",\n",
    "    examples=example_questions,\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 데모 실행\n",
    "demo.launch()"
   ],
   "id": "29e55c548d6eb619",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1bd26485",
   "metadata": {},
   "source": [
    "# 데모 종료\n",
    "demo.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "import logging\n",
    "\n",
    "# 설정할 로깅 레벨과 포맷 정의\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def answer_invoke(message: str, history: List[Tuple[str, str]]) -> str:\n",
    "    try:\n",
    "        logger.debug(f\"Received message: {message}\")\n",
    "        logger.debug(f\"Chat history: {history}\")\n",
    "\n",
    "        # 채팅 기록을 AI에게 전달할 수 있는 형식으로 변환\n",
    "        chat_history = []\n",
    "        for human, ai in history:\n",
    "            chat_history.append(HumanMessage(content=human))\n",
    "            chat_history.append(AIMessage(content=ai))\n",
    "        \n",
    "        logger.debug(f\"Formatted chat history: {chat_history[-4:]}\")\n",
    "        \n",
    "        # agent_executor를 사용하여 응답 생성\n",
    "        response = agent_executor.invoke({\n",
    "            \"input\": message,\n",
    "            \"chat_history\": chat_history[-4:]    # 최근 2개의 메시지 기록만을 활용 \n",
    "        })\n",
    "        \n",
    "        logger.debug(f\"Response from agent_executor: {response}\")\n",
    "        \n",
    "        # agent_executor의 응답에서 최종 답변 추출\n",
    "        return response['output']\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred: {str(e)}\")\n",
    "        return \"죄송합니다. 응답을 생성하는 동안 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "# 예제 질문 정의\n",
    "example_questions = [\n",
    "    \"시그니처 스테이크의 가격과 특징을 알려주세요.\",\n",
    "    \"트러플 리조또와 잘 어울리는 와인을 추천해주세요.\",\n",
    "    \"해산물 파스타의 주요 재료는 무엇인가요? 서울 강남 지역에 레스토랑을 추천해주세요.\",\n",
    "    \"채식주의자를 위한 메뉴 옵션이 있나요?\"\n",
    "]\n",
    "\n",
    "# Gradio 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,\n",
    "    title=\"레스토랑 메뉴 AI 어시스턴트\",\n",
    "    description=\"메뉴 정보, 추천, 음식 관련 질문에 답변해 드립니다.\",\n",
    "    examples=example_questions,\n",
    "    theme=gr.themes.Soft()\n",
    ")\n"
   ],
   "id": "75b4cf3f78e6bc4c"
  },
  {
   "cell_type": "code",
   "id": "9fb837bc",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
